# ML_for_metro_PM_v5.py
# åœ°é“é¢—ç²’ç‰©æµ“åº¦é¢„æµ‹åˆ†æç³»ç»Ÿ
# æ›´æ–°: 2026

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import randint, uniform
from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold
from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor, ExtraTreesRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
import lightgbm as lgb
import shap
import warnings
warnings.filterwarnings('ignore')

try:
    from skopt import BayesSearchCV
    from skopt.space import Real, Integer, Categorical
    BAYES_AVAILABLE = True
    print("âœ“ BayesSearchCV å¯ç”¨ï¼ˆè´å¶æ–¯ä¼˜åŒ–ï¼‰")
except ImportError:
    BAYES_AVAILABLE = False
    print("âš  BayesSearchCV ä¸å¯ç”¨ï¼Œå›é€€åˆ° RandomizedSearchCV")
    print("  å®‰è£…å‘½ä»¤: pip install scikit-optimize")

# ==================== è¾“å‡ºç›®å½•é…ç½® ====================
OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "output_results")
os.makedirs(OUTPUT_DIR, exist_ok=True)

def out_path(filename):
    """è¿”å›è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„"""
    return os.path.join(OUTPUT_DIR, filename)

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.max_open_warning'] = 50

# è®¾ç½®éšæœºç§å­
np.random.seed(42)

print("=" * 100)
print("åœ°é“é¢—ç²’ç‰©æµ“åº¦é¢„æµ‹åˆ†æç³»ç»Ÿ")
print("=" * 100)
# ==================== 1. æ•°æ®åŠ è½½å’Œé¢„å¤„ç† ====================
def load_and_preprocess_data(file_path):
    """åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼šå¼‚å¸¸å€¼å¤„ç† + é«˜çº§ç‰¹å¾å·¥ç¨‹ï¼‰"""
    print("\n" + "=" * 100)
    print("æ­¥éª¤ 1: æ•°æ®åŠ è½½å’Œé¢„å¤„ç†ï¼ˆå¢å¼ºç‰ˆï¼‰")
    print("=" * 100)
    
    df = pd.read_excel(file_path)
    
    print(f"\næ•°æ®é›†å½¢çŠ¶: {df.shape}")
    print(f"æ ·æœ¬æ•°é‡: {df.shape[0]}")
    print(f"ç‰¹å¾æ•°é‡: {df.shape[1] - 1}")
    

    # å®šä¹‰åŸå§‹ç‰¹å¾åˆ—å’Œç›®æ ‡åˆ—
    feature_cols = ['Peak', 'Platform depth', 'Metro humidity', 
                   'Outdoor humidity', 'Metro temperature', 'Outdoor temperature',
                   'Platform years', 'Line years', 'Screen doort ype',
                   'Platform type', 'Transfer station', 'Air pressure',
                   'Ground_PM']
    target_col = 'Metro_PM'
    
    X = df[feature_cols].copy()
    y = df[target_col].copy()
    
    # ---------- ç¼ºå¤±å€¼å¤„ç† ----------
    print("\nç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing_counts = X.isnull().sum()
    if missing_counts.sum() > 0:
        print(missing_counts[missing_counts > 0])
        for col in X.columns:
            if X[col].isnull().sum() > 0:
                X[col].fillna(X[col].median(), inplace=True)
    else:
        print("æ— ç¼ºå¤±å€¼")
    
    if y.isnull().sum() > 0:
        y.fillna(y.median(), inplace=True)
    
    # ---------- å¼‚å¸¸å€¼å¤„ç†ï¼ˆIQRæˆªæ–­æ³•ï¼‰----------
    print("\nå¼‚å¸¸å€¼å¤„ç† (IQRæ–¹æ³•)...")
    continuous_cols = ['Platform depth', 'Metro humidity', 'Outdoor humidity',
                       'Metro temperature', 'Outdoor temperature', 'Platform years',
                       'Line years', 'Air pressure', 'Ground_PM']
    n_clipped = 0
    for col in continuous_cols:
        if col in X.columns:
            Q1 = X[col].quantile(0.25)
            Q3 = X[col].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - 3.0 * IQR
            upper = Q3 + 3.0 * IQR
            before = ((X[col] < lower) | (X[col] > upper)).sum()
            X[col] = X[col].clip(lower, upper)
            if before > 0:
                n_clipped += before
                print(f"  {col}: æˆªæ–­ {before} ä¸ªæç«¯å€¼")
    if n_clipped == 0:
        print("  æ— æ˜æ˜¾å¼‚å¸¸å€¼")
    
    # ---------- é«˜çº§ç‰¹å¾å·¥ç¨‹----------
    print("\nç‰¹å¾å·¥ç¨‹: æ·»åŠ é«˜çº§äº¤äº’ç‰¹å¾...")
    
    # â”€â”€ åŸºç¡€äº¤äº’ç‰¹å¾â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    X['Temp_diff']             = X['Metro temperature'] - X['Outdoor temperature']
    X['Humidity_diff']         = X['Metro humidity'] - X['Outdoor humidity']
    X['Depth_age']             = X['Platform depth'] * X['Platform years']
    X['Peak_Transfer']         = X['Peak'] * X['Transfer station']
    X['Metro_THI']             = (X['Metro temperature'] 
                                  - (0.55 - 0.0055 * X['Metro humidity']) 
                                  * (X['Metro temperature'] - 14.5))
    X['PM_TempDiff']           = X['Ground_PM'] * X['Temp_diff']
    X['GroundPM_HumidityDiff'] = X['Ground_PM'] * X['Humidity_diff']
    X['GroundPM_Air_pressure'] = X['Ground_PM'] * X['Air pressure']

    # â”€â”€ æ–°å¢é«˜çº§ç‰¹å¾â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    X['Apparent_temp']     = (X['Metro temperature'] 
                               - 0.4 * (X['Metro temperature'] - 10) 
                               * (1 - X['Metro humidity'] / 100))
    X['Ventilation_proxy'] = X['Platform depth'] / (X['Platform years'] + 1)
    X['Relative_pressure'] = X['Air pressure'] - X['Air pressure'].mean()

    X['Type_Depth']      = X['Platform type'] * X['Platform depth']
    
    X['Age_composite']   = X['Platform years'] + 0.5 * X['Line years']
    
    X['GroundPM_TempDiff'] = X['Ground_PM'] * X['Temp_diff']

    # â”€â”€ â˜…å®šä¹‰ all_feature_colsï¼Œå†ä½¿ç”¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    new_features = [
        'Temp_diff', 'Humidity_diff', 'Depth_age',
        'Peak_Transfer', 'Metro_THI', 'PM_TempDiff',
        'GroundPM_HumidityDiff', 'GroundPM_Air_pressure',
        'Apparent_temp', 'Ventilation_proxy', 'Relative_pressure',
        'Type_Depth', 'Age_composite', 'GroundPM_TempDiff'
    ]
    
    all_feature_cols = feature_cols + new_features
    
    print(f"  æ–°å¢ {len(new_features)} ä¸ªé«˜çº§ç‰¹å¾")
    
    # â”€â”€ éªŒè¯æ‰€æœ‰ç‰¹å¾åˆ—æ˜¯å¦å­˜åœ¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n===== ç‰¹å¾åˆ—éªŒè¯ =====")
    missing_cols = [c for c in all_feature_cols if c not in X.columns]
    found_cols   = [c for c in all_feature_cols if c in X.columns]
    
    for c in all_feature_cols:
        status = "âœ…" if c in X.columns else "âŒ ç¼ºå¤±"
        print(f"  {status} '{c}'")
    
    if missing_cols:
        raise ValueError(
            f"\nâŒ ä»¥ä¸‹ç‰¹å¾åˆ—æœªç”Ÿæˆï¼š{missing_cols}\n"
            f"è¯·æ£€æŸ¥ç‰¹å¾å·¥ç¨‹ä»£ç æ˜¯å¦å®Œæ•´"
        )
    else:
        print(f"\nâœ… å…¨éƒ¨ {len(all_feature_cols)} ä¸ªç‰¹å¾åˆ—éªŒè¯é€šè¿‡")

    # ---------- ç‰¹å¾ç­›é€‰ï¼šå»é™¤é«˜åº¦å…±çº¿ç‰¹å¾ï¼ˆ|r| > 0.95ï¼‰----------
    print("\nç‰¹å¾ç­›é€‰: å»é™¤é«˜å…±çº¿æ€§ç‰¹å¾...")
    corr_mat = X[all_feature_cols].corr().abs()
    upper = corr_mat.where(np.triu(np.ones(corr_mat.shape), k=1).astype(bool))
    drop_cols = [col for col in upper.columns if any(upper[col] > 0.95)]
    if drop_cols:
        print(f"  ç§»é™¤é«˜å…±çº¿æ€§ç‰¹å¾ (|r|>0.95): {drop_cols}")
        X.drop(columns=drop_cols, inplace=True)
        all_feature_cols = [c for c in all_feature_cols if c not in drop_cols]
    else:
        print("  æ— é«˜å…±çº¿æ€§ç‰¹å¾éœ€ç§»é™¤")
    print(f"  æœ€ç»ˆç‰¹å¾æ•°: {len(all_feature_cols)}")

    # ---------- ç›®æ ‡å˜é‡ç»Ÿè®¡ ----------
    print("\nç›®æ ‡å˜é‡ç»Ÿè®¡æè¿°:")
    print(f"å‡å€¼: {y.mean():.4f}  æ ‡å‡†å·®: {y.std():.4f}")
    print(f"æœ€å°å€¼: {y.min():.4f}  æœ€å¤§å€¼: {y.max():.4f}  ä¸­ä½æ•°: {y.median():.4f}")
    
    # ---------- æ•°æ®é›†åˆ’åˆ† ----------
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    print(f"\nè®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬ ({X_train.shape[0]/len(X)*100:.1f}%)")
    print(f"æµ‹è¯•é›†:  {X_test.shape[0]} æ ·æœ¬ ({X_test.shape[0]/len(X)*100:.1f}%)")
    
    # ---------- ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆRobustScalerï¼‰----------
    scaler = RobustScaler()
    X_train_scaled = pd.DataFrame(
        scaler.fit_transform(X_train),
        columns=X_train.columns,
        index=X_train.index
    )
    X_test_scaled = pd.DataFrame(
        scaler.transform(X_test),
        columns=X_test.columns,
        index=X_test.index
    )
    print("ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ (RobustScaler)")
    
    return X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, all_feature_cols

# ==================== æ®‹å·®é©±åŠ¨æ•°æ®å¢å¼º ====================
def residual_based_augmentation(X, y, n_aug=2, noise_scale=0.15):
    """
    åŸºäºæ®‹å·®çš„æ•°æ®å¢å¼ºï¼ˆé€‚é…å°æ ·æœ¬ï¼Œä¸é™å®šåŸå¸‚ï¼‰
    
    X: åŸå§‹ç‰¹å¾ DataFrame
    y: åŸå§‹ç›®æ ‡ Seriesï¼ˆåœ°é“PMå€¼ï¼‰
    n_aug: æ¯ä¸ªæ ·æœ¬ç”Ÿæˆå‡ ä¸ªå¢å¼ºæ ·æœ¬ï¼ˆå°æ ·æœ¬æ¨è1ï¼‰
    noise_scale: å™ªå£°å¼ºåº¦ï¼ˆå°æ ·æœ¬æ¨è0.1~0.3ï¼Œç»å¯¹ä¸è¶…è¿‡0.4ï¼‰
    """
    #  1. æå‰åˆå§‹åŒ–æ‰€æœ‰å…³é”®å˜é‡ï¼Œè§£å†³Pylanceæœªå®šä¹‰æŠ¥é”™
    sigma = 1.0
    X_aug_list = []  # æå‰å£°æ˜ç©ºåˆ—è¡¨
    y_aug_list = []  # æå‰å£°æ˜ç©ºåˆ—è¡¨

    # 2. æ‹ŸåˆåŸºå‡†çº¿æ€§æ¨¡å‹ï¼ˆå°æ ·æœ¬ç”¨æ›´å¼ºæ­£åˆ™ï¼Œé¿å…åŸºå‡†æ¨¡å‹è¿‡æ‹Ÿåˆï¼‰
    base_model = Ridge(alpha=100.0)  # å°æ ·æœ¬å¢å¼ºæ­£åˆ™
    base_model.fit(X, y)

    y_pred = base_model.predict(X)
    residuals = y - y_pred

    # 3. é‡æ–°èµ‹å€¼æ®‹å·®åˆ†å¸ƒå‚æ•°ï¼ˆè¦†ç›–åˆå§‹å€¼ï¼Œé€»è¾‘ä¸å˜ï¼‰
    mu = 0  # å°æ ·æœ¬æ®‹å·®å‡å€¼ç½®0ï¼Œé¿å…ç³»ç»Ÿåå·®
    sigma = residuals.std()

    # 4. å®šä¹‰è¿ç»­ç‰¹å¾åˆ—ï¼ˆä»…å¯¹è¿™äº›ç‰¹å¾åŠ å¾®å°å™ªå£°ï¼Œåˆ†ç±»ç‰¹å¾ä¸å˜ï¼‰
    continuous_cols = ['Platform depth', 'Metro humidity', 'Outdoor humidity', 
                       'Metro temperature', 'Outdoor temperature', 
                       'Air pressure', 'Ground_PM']
    # æé«˜ç‰¹å¾å™ªå£°çš„ç²¾ç»†åº¦ï¼Œåˆ†ç‰¹å¾è®¾ç½®ä¸åŒå™ªå£°å¼ºåº¦ï¼ˆè´´åˆä¸šåŠ¡å®é™…ï¼Œé¿å…å…³é”®ç‰¹å¾è¿‡åº¦æ‰°åŠ¨ï¼‰
    feat_noise_scale_map = {
        'Platform depth': 0.005, 'Metro humidity': 0.01, 'Outdoor humidity': 0.01,
        'Metro temperature': 0.008, 'Outdoor temperature': 0.008,
        'Air pressure': 0.001, 'Ground_PM': 0.015  # Ground_PMä¸ºæ ¸å¿ƒç‰¹å¾ï¼Œå™ªå£°ç¨é«˜ä½†ä¸è¶…0.02
    }

    # 5. ç”Ÿæˆå¢å¼ºæ ·æœ¬
    for _ in range(n_aug):
        # æ ‡ç­¾å™ªå£°ï¼šè¿›ä¸€æ­¥é™ä½å¼ºåº¦+æ›´ä¸¥æ ¼çš„å€¼åŸŸçº¦æŸï¼ˆåŸ1.1â†’1.05ï¼Œé¿å…ç”Ÿæˆä¸åˆç†çš„PMå€¼ï¼‰
        noise = np.random.normal(mu, sigma * noise_scale, size=len(y))
        y_new = y_pred + noise
        y_new = np.clip(y_new, 0, y.max() * 1.05)  # ä¸Šé™ä¸è¶…è¿‡åŸæœ€å¤§å€¼çš„105%
        
        # ç‰¹å¾å™ªå£°ï¼šæŒ‰ç‰¹å¾ä¸ªæ€§åŒ–è®¾ç½®å™ªå£°å¼ºåº¦ï¼Œè€Œéç»Ÿä¸€0.01
        X_new = X.copy()
        for col in continuous_cols:
            if col in X_new.columns:
                feat_noise = np.random.normal(0, X_new[col].std() * feat_noise_scale_map[col], size=len(X_new))
                X_new[col] += feat_noise
                # æ›´ä¸¥æ ¼çš„ä¸šåŠ¡å€¼åŸŸçº¦æŸï¼Œé¿å…ç”Ÿæˆä¸åˆç†ç‰¹å¾å€¼
                if 'humidity' in col.lower():
                    X_new[col] = np.clip(X_new[col], 20, 95)  # æ¹¿åº¦20-95%ï¼ˆåŸ0-100ï¼Œæ’é™¤æç«¯æ— æ„ä¹‰å€¼ï¼‰
                elif 'temperature' in col.lower():
                    X_new[col] = np.clip(X_new[col], 10, 35)  # æ¸©åº¦10-35â„ƒï¼ˆåŸ-10-40ï¼Œè´´åˆåœ°é“å®é™…ï¼‰
                elif 'Platform depth' in col:
                    X_new[col] = np.clip(X_new[col], 5, 25)  # ç«™å°æ·±åº¦5-25mï¼ˆåŸ1-30ï¼Œæ’é™¤æç«¯å€¼ï¼‰
                elif 'PM' in col:
                    X_new[col] = np.clip(X_new[col], 0, 300)  # åœ°é¢PM0-300ï¼ˆåŸ0-500ï¼Œè´´åˆå®é™…ç›‘æµ‹èŒƒå›´ï¼‰
                elif 'Air pressure' in col:
                    X_new[col] = np.clip(X_new[col], 980, 1050)  # æ°”å‹980-1050hPaï¼Œè´´åˆå®é™…
        
        # æ–°å¢ï¼šå¯¹åˆ†ç±»ç‰¹å¾è¿›è¡Œè½»å¾®æ‰°åŠ¨
        categorical_cols = ['Peak', 'Transfer station']  # ç¦»æ•£åˆ†ç±»ç‰¹å¾
        for col in categorical_cols:
            if col in X_new.columns:
                # 5%çš„æ¦‚ç‡ç¿»è½¬åˆ†ç±»å€¼ï¼Œé¿å…åˆ†ç±»ç‰¹å¾å®Œå…¨ä¸å˜
                flip_mask = np.random.choice([True, False], size=len(X_new), p=[0.05, 0.95])
                X_new.loc[flip_mask, col] = 1 - X_new.loc[flip_mask, col]
        
        X_aug_list.append(X_new)
        y_aug_list.append(pd.Series(y_new, index=y.index))
    
    X_aug = pd.concat(X_aug_list, axis=0)
    y_aug = pd.concat(y_aug_list, axis=0)
    return X_aug, y_aug

# ==================== 2. Adaptive LASSOå®ç° ====================
class AdaptiveLasso:
    """Adaptive LASSOå›å½’å®ç°"""
    def __init__(self, alpha=1.0, gamma=1.0, max_iter=10000):
        self.alpha = alpha
        self.gamma = gamma
        self.max_iter = max_iter
        self.coef_ = None
        self.intercept_ = None
        
    def fit(self, X, y):
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨Ridgeå›å½’è·å¾—åˆå§‹æƒé‡
        ridge = Ridge(alpha=0.1)
        ridge.fit(X, y)
        ridge_coef = np.abs(ridge.coef_)
        
        # è®¡ç®—è‡ªé€‚åº”æƒé‡
        weights = 1.0 / (ridge_coef ** self.gamma + 1e-8)
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨åŠ æƒçš„LASSO
        X_weighted = X * weights
        
        lasso = Lasso(alpha=self.alpha, max_iter=self.max_iter)
        lasso.fit(X_weighted, y)
        
        self.coef_ = lasso.coef_ * weights
        self.intercept_ = lasso.intercept_
        
        return self
    
    def predict(self, X):
        return X @ self.coef_ + self.intercept_
    
    def get_params(self, deep=True):
        return {'alpha': self.alpha, 'gamma': self.gamma, 'max_iter': self.max_iter}
    
    def set_params(self, **params):
        for key, value in params.items():
            setattr(self, key, value)
        return self

# ==================== 3. æ¨¡å‹å®šä¹‰ï¼ˆè´å¶æ–¯æœç´¢ç©ºé—´ç‰ˆï¼‰====================
def get_models_and_params(n_train=360):
    """
    æ¨¡å‹å®šä¹‰ â€”â€” è´å¶æ–¯ä¼˜åŒ–ç‰ˆ
    """

    if BAYES_AVAILABLE:
        models = {
            'Ridge': {
                'model': Ridge(),
                'params': {
                    'alpha': Real(1e-3, 1e3, prior='log-uniform'),
                },
                'use_scaled': True, 'n_iter': 40
            },
            'Lasso': {
                'model': Lasso(max_iter=50000),
                'params': {
                    'alpha': Real(1e-3, 50.0, prior='log-uniform'),
                },
                'use_scaled': True, 'n_iter': 40
            },
            'ElasticNet': {
                'model': ElasticNet(max_iter=35000),
                'params': {
                    'alpha':    Real(1e-3, 10.0, prior='log-uniform'),
                    'l1_ratio': Real(0.05, 0.95, prior='uniform'),
                },
                'use_scaled': True, 'n_iter': 40
            },
            'Adaptive Lasso': {
                'model': AdaptiveLasso(),
                'params': {
                    'alpha': Real(1e-3, 10.0, prior='log-uniform'),
                    'gamma': Real(0.3, 2.5,  prior='uniform'),
                },
                'use_scaled': True, 'n_iter': 35
            },
            'Random Forest': {
                'model': RandomForestRegressor(
                    random_state=42, n_jobs=-1, oob_score=True),
                'params': {
                    'n_estimators':      Integer(100, 600),
                    'max_depth':         Integer(3, 8),
                    'min_samples_split': Integer(2, 20),
                    'min_samples_leaf':  Integer(1, 10),
                    'max_features':      Real(0.3, 0.9, prior='uniform'),
                    'max_samples':       Real(0.6, 0.95, prior='uniform'),
                },
                'use_scaled': False, 'n_iter': 60
            },
            'Extra Trees': {
                'model': ExtraTreesRegressor(random_state=42, n_jobs=-1),
                'params': {
                    'n_estimators':      Integer(100, 500),
                    'max_depth':         Integer(3, 8),
                    'min_samples_split': Integer(2, 20),
                    'min_samples_leaf':  Integer(1, 10),
                    'max_features':      Real(0.3, 0.9, prior='uniform'),
                },
                'use_scaled': False, 'n_iter': 50
            },
            'XGBoost': {
                'model': XGBRegressor(
                    random_state=42, n_jobs=-1,
                    tree_method='hist', eval_metric='rmse'),
                'params': {
                    'n_estimators':      Integer(100, 600),
                    'max_depth':         Integer(2, 6),
                    'learning_rate':     Real(0.005, 0.3,  prior='log-uniform'),
                    'subsample':         Real(0.6, 1.0,   prior='uniform'),
                    'colsample_bytree':  Real(0.6, 1.0,   prior='uniform'),
                    'reg_alpha':         Real(1e-4, 50.0, prior='log-uniform'),
                    'reg_lambda':        Real(1e-4, 100.0,prior='log-uniform'),
                    'min_child_weight':  Integer(1, 20),
                    'gamma':             Real(0.0, 5.0,   prior='uniform'),
                },
                'use_scaled': False, 'n_iter': 70
            },
            'Gradient Boosting': {
                'model': GradientBoostingRegressor(random_state=42),
                'params': {
                    'n_estimators':      Integer(100, 400),
                    'max_depth':         Integer(2, 5),
                    'learning_rate':     Real(0.005, 0.2, prior='log-uniform'),
                    'subsample':         Real(0.6, 1.0,  prior='uniform'),
                    'min_samples_split': Integer(2, 20),
                    'min_samples_leaf':  Integer(1, 10),
                    'max_features':      Real(0.3, 0.9,  prior='uniform'),
                    'validation_fraction': Real(0.1, 0.2, prior='uniform'),
                    'n_iter_no_change':  Integer(10, 30),
                },
                'use_scaled': False, 'n_iter': 60
            },
            'KNN': {
                'model': KNeighborsRegressor(n_jobs=-1),
                'params': {
                    'n_neighbors': Integer(3, 15),
                    'weights':     Categorical(['distance', 'uniform']),
                    'metric':      Categorical(['euclidean', 'manhattan']),
                },
                'use_scaled': True, 'n_iter': 30
            },
            'SVM': {
                'model': SVR(),
                'params': {
                    'C':       Real(0.1, 100.0, prior='log-uniform'),
                    'gamma':   Categorical(['scale', 'auto']),
                    'kernel':  Categorical(['rbf', 'linear']),
                    'epsilon': Real(0.01, 0.5,  prior='log-uniform'),
                },
                'use_scaled': True, 'n_iter': 40
            },
        }

        if LGBM_AVAILABLE:
            models['LightGBM'] = {
                'model': lgb.LGBMRegressor(
                    random_state=42, n_jobs=-1, verbose=-1),
                'params': {
                    'n_estimators':      Integer(100, 600),
                    'max_depth':         Integer(3, 7),
                    'learning_rate':     Real(0.005, 0.3,  prior='log-uniform'),
                    'num_leaves':        Integer(10, 80),
                    'subsample':         Real(0.6, 1.0,   prior='uniform'),
                    'colsample_bytree':  Real(0.6, 1.0,   prior='uniform'),
                    'reg_alpha':         Real(1e-4, 50.0, prior='log-uniform'),
                    'reg_lambda':        Real(1e-4, 100.0,prior='log-uniform'),
                    'min_child_samples': Integer(3, 50),
                    'path_smooth':       Real(0.0, 2.0,   prior='uniform'),
                },
                'use_scaled': False, 'n_iter': 70
            }
            print("âœ“ LightGBMï¼ˆè´å¶æ–¯æœç´¢ç©ºé—´ï¼‰å·²åŠ è½½")

    else:
        models = {
            'Ridge': {
                'model': Ridge(),
                'params': {
                    'alpha': [0.01, 0.1, 1.0, 10.0, 50.0, 100.0, 500.0],
                    'solver': ['auto', 'lsqr', 'saga']
                },
                'use_scaled': True, 'n_iter': 30
            },
            'Lasso': {
                'model': Lasso(max_iter=50000),
                'params': {
                    'alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0],
                    'selection': ['random', 'cyclic']
                },
                'use_scaled': True, 'n_iter': 25
            },
            'ElasticNet': {
                'model': ElasticNet(max_iter=35000),
                'params': {
                    'alpha':    [0.01, 0.1, 0.5, 1.0, 5.0],
                    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],
                    'selection': ['random']
                },
                'use_scaled': True, 'n_iter': 25
            },
            'Adaptive Lasso': {
                'model': AdaptiveLasso(),
                'params': {
                    'alpha': [0.01, 0.1, 0.5, 1.0, 5.0],
                    'gamma': [0.5, 0.8, 1.0, 1.5, 2.0]
                },
                'use_scaled': True, 'n_iter': 25
            },
            'Random Forest': {
                'model': RandomForestRegressor(
                    random_state=42, n_jobs=-1, oob_score=True),
                'params': {
                    'n_estimators':      [100, 200, 300, 500],
                    'max_depth':         [3, 4, 5, 6, None],
                    'min_samples_split': [2, 5, 10, 15],
                    'min_samples_leaf':  [1, 3, 5, 8],
                    'max_features':      ['sqrt', 'log2', 0.5, 0.7],
                    'max_samples':       [0.7, 0.8, 0.9],
                },
                'use_scaled': False, 'n_iter': 50
            },
            'Extra Trees': {
                'model': ExtraTreesRegressor(random_state=42, n_jobs=-1),
                'params': {
                    'n_estimators':      [100, 200, 300],
                    'max_depth':         [3, 4, 5, None],
                    'min_samples_split': [2, 5, 10, 15],
                    'min_samples_leaf':  [1, 3, 5, 8],
                    'max_features':      ['sqrt', 'log2', 0.5]
                },
                'use_scaled': False, 'n_iter': 40
            },
            'XGBoost': {
                'model': XGBRegressor(
                    random_state=42, n_jobs=-1,
                    tree_method='hist', eval_metric='rmse'),
                'params': {
                    'n_estimators':     [100, 200, 300, 500],
                    'max_depth':        [2, 3, 4, 5],
                    'learning_rate':    [0.01, 0.05, 0.1, 0.2],
                    'subsample':        [0.7, 0.8, 0.9],
                    'colsample_bytree': [0.7, 0.8, 0.9],
                    'reg_alpha':        [0.0, 0.1, 1.0, 10.0, 50.0],
                    'reg_lambda':       [0.1, 1.0, 10.0, 50.0],
                    'min_child_weight': [1, 3, 5, 10],
                    'gamma':            [0.0, 0.1, 1.0, 5.0],
                },
                'use_scaled': False, 'n_iter': 60
            },
            'Gradient Boosting': {
                'model': GradientBoostingRegressor(random_state=42),
                'params': {
                    'n_estimators':      [100, 200, 300],
                    'max_depth':         [2, 3, 4],
                    'learning_rate':     [0.01, 0.05, 0.1],
                    'subsample':         [0.7, 0.8, 0.9],
                    'min_samples_split': [2, 5, 10],
                    'min_samples_leaf':  [1, 3, 5],
                    'max_features':      ['sqrt', 0.5, 0.7],
                    'validation_fraction': [0.15],
                    'n_iter_no_change':  [20],
                    'tol':               [1e-4]
                },
                'use_scaled': False, 'n_iter': 50
            },
            'KNN': {
                'model': KNeighborsRegressor(n_jobs=-1),
                'params': {
                    'n_neighbors': [3, 5, 7, 9, 11],
                    'weights':     ['distance', 'uniform'],
                    'metric':      ['euclidean', 'manhattan'],
                },
                'use_scaled': True, 'n_iter': 20
            },
            'SVM': {
                'model': SVR(),
                'params': {
                    'C':       [0.5, 1.0, 5.0, 10.0, 50.0],
                    'gamma':   ['scale', 'auto'],
                    'kernel':  ['rbf', 'linear'],
                    'epsilon': [0.05, 0.1, 0.2],
                },
                'use_scaled': True, 'n_iter': 30
            },
        }

        if LGBM_AVAILABLE:
            models['LightGBM'] = {
                'model': lgb.LGBMRegressor(
                    random_state=42, n_jobs=-1, verbose=-1),
                'params': {
                    'n_estimators':      [100, 200, 300],
                    'max_depth':         [3, 4, 5, 6],
                    'learning_rate':     [0.01, 0.05, 0.1],
                    'num_leaves':        [15, 31, 50, 63],
                    'subsample':         [0.7, 0.8, 0.9],
                    'colsample_bytree':  [0.7, 0.8, 0.9],
                    'reg_alpha':         [0.0, 0.1, 1.0, 10.0],
                                        'reg_lambda':        [0.1, 1.0, 10.0, 50.0],
                    'min_child_samples': [5, 10, 20, 30],
                    'path_smooth':       [0.0, 1.0, 2.0],
                },
                'use_scaled': False, 'n_iter': 60
            }
            print("âœ“ LightGBMï¼ˆéšæœºæœç´¢ç©ºé—´ï¼‰å·²åŠ è½½")

    return models


# ==================== 4. æœç´¢å™¨æ„å»ºå‡½æ•°====================
def build_search(model, params, n_iter, n_cv):
    """
    æ ¹æ®å¯ç”¨åº“è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æœç´¢ç­–ç•¥ï¼š
    è´å¶æ–¯ä¼˜åŒ–ï¼ˆBayesSearchCVï¼‰> éšæœºæœç´¢ï¼ˆRandomizedSearchCVï¼‰

    è¿”å›ï¼š(searchå¯¹è±¡, æœç´¢æ–¹å¼æè¿°å­—ç¬¦ä¸²)
    """
    if BAYES_AVAILABLE:
        try:
            search = BayesSearchCV(
                estimator   = model,
                search_spaces = params,
                n_iter      = n_iter,
                cv          = n_cv,
                scoring     = 'r2',
                n_jobs      = -1,
                random_state= 42,
                verbose     = 0,
                refit       = True,
                return_train_score = True,
                optimizer_kwargs   = {'base_estimator': 'GP',  # é«˜æ–¯è¿‡ç¨‹ä»£ç†æ¨¡å‹
                                      'acq_func': 'EI'}        # æœŸæœ›æå‡é‡‡é›†å‡½æ•°
            )
            return search, "è´å¶æ–¯ä¼˜åŒ–ï¼ˆBayesSearchCVÂ·GPÂ·EIï¼‰"
        except Exception as e:
            print(f"  âš  BayesSearchCVåˆå§‹åŒ–å¤±è´¥ï¼ˆ{e}ï¼‰ï¼Œå›é€€éšæœºæœç´¢")

    # å…œåº•ï¼šéšæœºæœç´¢
    search = RandomizedSearchCV(
        estimator   = model,
        param_distributions = params,
        n_iter      = n_iter,
        cv          = n_cv,
        scoring     = 'r2',
        n_jobs      = -1,
        random_state= 42,
        verbose     = 0,
        refit       = True,
        error_score = 'raise',
        return_train_score = True
    )
    return search, "éšæœºæœç´¢ï¼ˆRandomizedSearchCVï¼‰"


# ==================== 4. æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°====================
def train_and_evaluate_models(X_train, X_test, y_train, y_test,
                               X_train_scaled, X_test_scaled):
    """
    æ¨¡å‹è®­ç»ƒ â€”â€” è´å¶æ–¯ä¼˜åŒ– + å®Œæ•´è¿‡æ‹Ÿåˆè¯Šæ–­ç‰ˆ

    ä¼˜åŒ–ç‚¹ï¼š
    1. è‡ªåŠ¨é€‰æ‹© BayesSearchCV / RandomizedSearchCV
    2. å®Œæ•´è¿‡æ‹Ÿåˆè¯Šæ–­ï¼ˆä¿®å¤ç¼©è¿›Bugï¼‰
    3. è®­ç»ƒé›†CVå‡å€¼åŒæ­¥è¾“å‡º
    4. StackingåŸºäºCV-RÂ²é€‰Top3
    """
    n_train = len(X_train)
    n_cv    = 5 if n_train >= 300 else 5   # â˜… æ ·æœ¬è¶³å¤Ÿæ—¶ç”¨10æŠ˜
    models_config = get_models_and_params(n_train=n_train)
    results        = {}
    trained_models = {}

    search_mode = "è´å¶æ–¯ä¼˜åŒ–" if BAYES_AVAILABLE else "éšæœºæœç´¢"
    print("\n" + "=" * 100)
    print(f"æ­¥éª¤ 2: æ¨¡å‹è®­ç»ƒï¼ˆ{search_mode}ï¼Œ{n_cv}æŠ˜CVï¼‰")
    print("=" * 100)
    print(f"è®­ç»ƒé›†: {n_train} æ ·æœ¬ | äº¤å‰éªŒè¯: {n_cv}æŠ˜ | å…± {len(models_config)} ä¸ªæ¨¡å‹")

    for idx, (model_name, config) in enumerate(models_config.items(), 1):
        print(f"\n[{idx}/{len(models_config)}] {model_name}")
        print("-" * 80)

        if config['use_scaled']:
            X_tr, X_te = X_train_scaled, X_test_scaled
            print("  æ•°æ®: æ ‡å‡†åŒ–ï¼ˆRobustScalerï¼‰")
        else:
            X_tr, X_te = X_train, X_test
            print("  æ•°æ®: åŸå§‹")

        try:
            # â”€â”€ è‡ªåŠ¨é€‰æ‹©æœç´¢å™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            n_iter = config.get('n_iter', 40)
            search, search_desc = build_search(
                config['model'], config['params'], n_iter, n_cv)
            print(f"  æœç´¢ç­–ç•¥: {search_desc}ï¼ˆn_iter={n_iter}ï¼‰")

            search.fit(X_tr, y_train)

            best_model  = search.best_estimator_
            best_params = search.best_params_

            # â”€â”€ è®­ç»ƒé›† & æµ‹è¯•é›†é¢„æµ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            y_pred_train = best_model.predict(X_tr)
            y_pred_test  = best_model.predict(X_te)

            train_r2   = r2_score(y_train, y_pred_train)
            train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
            train_mae  = mean_absolute_error(y_train, y_pred_train)

            # â”€â”€ äº¤å‰éªŒè¯ï¼ˆå†æ¬¡è¯„ä¼°ï¼Œç¡®ä¿ç¨³å¥ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            cv_scores = cross_val_score(
                best_model, X_tr, y_train,
                cv=n_cv, scoring='r2', n_jobs=-1)

            # â”€â”€ æµ‹è¯•é›†æŒ‡æ ‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            test_r2   = r2_score(y_test, y_pred_test)
            test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
            test_mae  = mean_absolute_error(y_test, y_pred_test)
            mask      = y_test != 0
            test_mape = np.mean(
                np.abs((y_test[mask] - y_pred_test[mask]) / y_test[mask])
            ) * 100
            gap = train_r2 - test_r2

            # â”€â”€ è´å¶æ–¯æœç´¢é¢å¤–ä¿¡æ¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if BAYES_AVAILABLE and hasattr(search, 'best_score_'):
                cv_best_score = search.best_score_
            else:
                cv_best_score = cv_scores.mean()

            results[model_name] = {
                'best_params'  : dict(best_params),   # â˜… ç»Ÿä¸€è½¬dict
                'train_r2'     : train_r2,
                'test_r2'      : test_r2,
                'train_rmse'   : train_rmse,
                'test_rmse'    : test_rmse,
                'train_mae'    : train_mae,
                'test_mae'     : test_mae,
                'test_mape'    : test_mape,
                'cv_r2_mean'   : cv_scores.mean(),
                'cv_r2_std'    : cv_scores.std(),
                'cv_best_score': cv_best_score,
                'overfit_gap'  : gap,
                'y_pred_train' : y_pred_train,
                'y_pred_test'  : y_pred_test,
                'search_mode'  : search_desc           # â˜… è®°å½•æœç´¢æ–¹å¼
            }
            trained_models[model_name] = {
                'model'        : best_model,
                'use_scaled'   : config['use_scaled'],
                'test_r2'      : test_r2,
                'trained_model': best_model
            }

            print(f"  æœ€ä½³å‚æ•°: {dict(best_params)}")
            print(f"  è®­ç»ƒé›† RÂ²={train_r2:.4f} | RMSE={train_rmse:.4f} | MAE={train_mae:.4f}")
            print(f"  æµ‹è¯•é›† RÂ²={test_r2:.4f} | RMSE={test_rmse:.4f} | "
                  f"MAE={test_mae:.4f} | MAPE={test_mape:.2f}%")
            print(f"  CV RÂ²({n_cv}æŠ˜): {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}"
                  f"  [æœç´¢æœ€ä¼˜CV={cv_best_score:.4f}]")

            # â”€â”€ è¿‡æ‹Ÿåˆè¯Šæ–­ç»Ÿä¸€åœ¨åˆ¤æ–­å—å¤–æ‰“å° â”€â”€
            if gap > 0.20:
                lvl = "ğŸ”´ ä¸¥é‡è¿‡æ‹Ÿåˆ"
                tip = "å¤§å¹…æé«˜æ­£åˆ™åŒ–ï¼›é™ä½ max_depthï¼›å¢å¤§ min_samples_leaf/min_child_weight"
            elif gap > 0.12:
                lvl = "ğŸŸ  æ˜æ˜¾è¿‡æ‹Ÿåˆ"
                tip = "é€‚å½“å¢å¤§æ­£åˆ™åŒ–ï¼›æ£€æŸ¥ max_depth å’Œå¶èŠ‚ç‚¹æ ·æœ¬æ•°è®¾ç½®"
            elif gap > 0.05:
                lvl = "ğŸŸ¡ è½»å¾®è¿‡æ‹Ÿåˆ"
                tip = "å¯æ¥å—èŒƒå›´ï¼Œå¯å¾®è°ƒæ­£åˆ™åŒ–å‚æ•°"
            else:
                lvl = "ğŸŸ¢ æ³›åŒ–è‰¯å¥½"
                tip = "è®­ç»ƒ/æµ‹è¯•ä¸€è‡´ï¼Œæ¨¡å‹å¯é "

            # â˜… æ‰€æœ‰æ¨¡å‹éƒ½æ‰“å°çŠ¶æ€
            print(f"  è¿‡æ‹Ÿåˆè¯Šæ–­: {lvl}ï¼ˆGap={gap:+.4f}ï¼‰")
            if gap > 0.05:
                print(f"  ğŸ’¡ å»ºè®®: {tip}")

        except Exception as e:
            print(f"  âŒ è®­ç»ƒå¤±è´¥: {e}")
            import traceback; traceback.print_exc()
            continue

    # â”€â”€ Stackingï¼ˆæŒ‰CV-RÂ²é€‰Top3æ ‘æ¨¡å‹ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\n[{len(models_config)+1}/{len(models_config)+1}] Stackingé›†æˆ")
    print("-" * 80)
    try:
        tree_names = ['Random Forest', 'Extra Trees', 'XGBoost',
                      'Gradient Boosting', 'LightGBM']
        candidates = [
            (n, results[n]['cv_r2_mean'], trained_models[n])
            for n in tree_names if n in results and n in trained_models
        ]
        candidates.sort(key=lambda x: x[1], reverse=True)
        top3 = candidates[:3]

        if len(top3) >= 2:
            base_ests = [
                (n.replace(' ', '_'), info['model'])
                for n, _, info in top3
            ]
            print(f"  åŸºæ¨¡å‹: {[(n, f'CV={s:.4f}') for n,s,_ in top3]}")

            stacking = StackingRegressor(
                estimators     = base_ests,
                final_estimator= Ridge(alpha=50.0),  # â˜… é™ä½å…ƒæ¨¡å‹æ­£åˆ™åŒ–
                cv             = n_cv,
                n_jobs         = -1,
                passthrough    = False
            )
            stacking.fit(X_train, y_train)

            ytr_st = stacking.predict(X_train)
            yte_st = stacking.predict(X_test)

            st_tr_r2 = r2_score(y_train, ytr_st)
            st_te_r2 = r2_score(y_test,  yte_st)
            st_rmse  = np.sqrt(mean_squared_error(y_test, yte_st))
            st_mae   = mean_absolute_error(y_test, yte_st)
            mask     = y_test != 0
            st_mape  = np.mean(
                np.abs((y_test[mask]-yte_st[mask])/y_test[mask]))*100
            st_cv    = cross_val_score(
                stacking, X_train, y_train,
                cv=n_cv, scoring='r2', n_jobs=-1)
            st_gap   = st_tr_r2 - st_te_r2

            results['Stacking'] = {
                'best_params'  : {'base': [n for n,_,_ in top3],
                                  'meta': 'Ridge(alpha=50)'},
                'train_r2'     : st_tr_r2,
                'test_r2'      : st_te_r2,
                'train_rmse'   : np.sqrt(mean_squared_error(y_train, ytr_st)),
                'test_rmse'    : st_rmse,
                'train_mae'    : mean_absolute_error(y_train, ytr_st),
                'test_mae'     : st_mae,
                'test_mape'    : st_mape,
                'cv_r2_mean'   : st_cv.mean(),
                'cv_r2_std'    : st_cv.std(),
                'cv_best_score': st_cv.mean(),
                'overfit_gap'  : st_gap,
                'y_pred_train' : ytr_st,
                'y_pred_test'  : yte_st,
                'search_mode'  : 'N/Aï¼ˆStackingæ— è¶…å‚æ•°æœç´¢ï¼‰'
            }
            trained_models['Stacking'] = {
                'model'        : stacking,
                'use_scaled'   : False,
                'test_r2'      : st_te_r2,
                'trained_model': stacking
            }

            print(f"  è®­ç»ƒé›† RÂ²={st_tr_r2:.4f}")
            print(f"  æµ‹è¯•é›† RÂ²={st_te_r2:.4f} | RMSE={st_rmse:.4f} | "
                  f"MAE={st_mae:.4f} | MAPE={st_mape:.2f}%")
            print(f"  CV RÂ²({n_cv}æŠ˜): {st_cv.mean():.4f} Â± {st_cv.std():.4f}")

            # è¿‡æ‹Ÿåˆè¯Šæ–­
            if st_gap > 0.20:   st_lvl = "ğŸ”´ ä¸¥é‡è¿‡æ‹Ÿåˆ"
            elif st_gap > 0.12: st_lvl = "ğŸŸ  æ˜æ˜¾è¿‡æ‹Ÿåˆ"
            elif st_gap > 0.05: st_lvl = "ğŸŸ¡ è½»å¾®è¿‡æ‹Ÿåˆ"
            else:               st_lvl = "ğŸŸ¢ æ³›åŒ–è‰¯å¥½"
            print(f"  è¿‡æ‹Ÿåˆè¯Šæ–­: {st_lvl}ï¼ˆGap={st_gap:+.4f}ï¼‰")
        else:
            print("  æ ‘æ¨¡å‹ä¸è¶³2ä¸ªï¼Œè·³è¿‡Stacking")

    except Exception as e:
        print(f"  âŒ Stackingå¤±è´¥: {e}")

    # â”€â”€ è®­ç»ƒæ€»ç»“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "=" * 100)
    print(f"è®­ç»ƒæ€»ç»“ï¼ˆ{search_mode}ï¼ŒæŒ‰æµ‹è¯•é›†RÂ²æ’åºï¼‰")
    print("=" * 100)
    sorted_r = sorted(results.items(),
                      key=lambda x: x[1]['test_r2'], reverse=True)
    print(f"{'æ¨¡å‹':<22} {'è®­ç»ƒRÂ²':>8} {'æµ‹è¯•RÂ²':>8} {'CV RÂ²':>8} "
          f"{'Gap':>8} {'çŠ¶æ€':<10} {'æœç´¢æ–¹å¼'}")
    print("-" * 100)
    for mn, r in sorted_r:
        g  = r.get('overfit_gap', r['train_r2'] - r['test_r2'])
        st = ("ğŸŸ¢è‰¯å¥½" if g <= 0.05 else
              "ğŸŸ¡è½»å¾®" if g <= 0.12 else
              "ğŸŸ æ˜æ˜¾" if g <= 0.20 else "ğŸ”´ä¸¥é‡")
        mode = r.get('search_mode', 'N/A')[:20]   # æˆªæ–­é¿å…è¿‡é•¿
        print(f"{mn:<22} {r['train_r2']:>8.4f} {r['test_r2']:>8.4f} "
              f"{r['cv_r2_mean']:>8.4f} {g:>+8.4f}  {st:<10} {mode}")

    return results, trained_models                                      

# ==================== 5. ç‰¹å¾é‡è¦æ€§åˆ†æ ====================
def analyze_feature_importance(models_dict, X_train, X_test, y_train, y_test, feature_cols):
    """åˆ†æç‰¹å¾é‡è¦æ€§"""
    print("\n" + "=" * 100)
    print("æ­¥éª¤ 3: ç‰¹å¾é‡è¦æ€§åˆ†æ")
    print("=" * 100)
    importance_results = {}
    from sklearn.inspection import permutation_importance
    
    for model_name, model_info in models_dict.items():
        try:
            # è·å–è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆä¿®å¤ï¼šä½¿ç”¨model_infoä¸­çš„trained_modelé”®ï¼‰
            model = model_info.get('trained_model', model_info['model'])
            X = X_train if model_info['use_scaled'] else X_train
            
            # 1. æ ‘æ¨¡å‹ï¼ˆRandomForest/XGBoost/LightGBM/GradientBoosting/ExtraTreesï¼‰
            if hasattr(model, 'feature_importances_'):
                importance = model.feature_importances_
            
            # 2. çº¿æ€§æ¨¡å‹ï¼ˆRidge/Lasso/ElasticNet/Adaptive Lassoï¼‰
            elif hasattr(model, 'coef_'):
                importance = np.abs(model.coef_)
                # å½’ä¸€åŒ–åˆ°0-1åŒºé—´
                if np.sum(importance) > 0:
                    importance = importance / np.sum(importance)
            
            # 3. KNN/SVMï¼ˆæ’åˆ—é‡è¦æ€§ï¼‰
            else:
                print(f"  {model_name}: è®¡ç®—æ’åˆ—é‡è¦æ€§ï¼ˆè€—æ—¶è¾ƒé•¿ï¼‰...")
                perm_result = permutation_importance(
                    model, X, y_train, n_repeats=10, random_state=42, n_jobs=-1
                )
                importance = perm_result.importances_mean
            
            # å­˜å‚¨ç»“æœ
            importance_results[model_name] = pd.Series(importance, index=X.columns).sort_values(ascending=False)
            
            # æ‰“å°TOP10ç‰¹å¾
            print(f"\n{model_name} ç‰¹å¾é‡è¦æ€§ï¼ˆTOP10ï¼‰:")
            print(importance_results[model_name].head(10))
            
        except Exception as e:
            print(f"  {model_name}: ç‰¹å¾é‡è¦æ€§è®¡ç®—å¤±è´¥ - {str(e)}")
            import traceback; traceback.print_exc()
            importance_results[model_name] = None
    
    # å¯è§†åŒ–TOP5ç‰¹å¾ï¼ˆä»¥æ€§èƒ½æœ€ä¼˜æ¨¡å‹ä¸ºä¾‹ï¼‰
    best_model_name = max(models_dict.keys(), key=lambda x: models_dict[x]['test_r2'] if 'test_r2' in models_dict[x] else 0)
    if importance_results[best_model_name] is not None and importance_results[best_model_name] is not None:
        plt.figure(figsize=(12, 8))
        top5_feat = importance_results[best_model_name].head(5)
        sns.barplot(x=top5_feat.values, y=top5_feat.index, palette='viridis')
        plt.title(f'{best_model_name} ç‰¹å¾é‡è¦æ€§ï¼ˆTOP5ï¼‰', fontsize=14)
        plt.xlabel('é‡è¦æ€§å€¼', fontsize=12)
        plt.ylabel('ç‰¹å¾åç§°', fontsize=12)
        plt.tight_layout()
        plt.savefig(out_path(f'{best_model_name}_feature_importance.png'), dpi=300)
        plt.close()
    
    return importance_results
# ==================== 6. SHAPå€¼åˆ†æï¼ˆå»é™¤TabPFNï¼‰====================
def analyze_shap_values(trained_models, X_train, X_test, X_train_scaled,
                        X_test_scaled, feature_names, y_train, y_test):
    """
    è®¡ç®—æ‰€æœ‰æ¨¡å‹çš„SHAPå€¼ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    ä¼˜åŒ–ç‚¹ï¼š
    1. å»é™¤TabPFNç›¸å…³ä»£ç 
    2. ä¼˜åŒ–é‡‡æ ·ç­–ç•¥æå‡é€Ÿåº¦
    3. ç»Ÿä¸€é”™è¯¯å¤„ç†æœºåˆ¶
    """
    shap_results = {}

    print("\n" + "=" * 100)
    print("æ­¥éª¤ 4: SHAPå€¼åˆ†æï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    print("=" * 100)

    for model_name, model_info in trained_models.items():
        print(f"\nè®¡ç®— {model_name} çš„SHAPå€¼...")
        print("-" * 80)

        model     = model_info['model']
        use_scaled= model_info['use_scaled']
        X_tr = X_train_scaled if use_scaled else X_train
        X_te = X_test_scaled  if use_scaled else X_test

        sv          = None   # shap values (2D array)
        base_val    = None
        X_sample    = None
        explainer   = None

        if model_name in ['Random Forest', 'XGBoost', 'Gradient Boosting',
                          'Extra Trees', 'LightGBM']:
            try:
                explainer = shap.TreeExplainer(model)
                X_sample  = X_te   # å…¨é‡æµ‹è¯•é›†
                raw       = explainer.shap_values(X_sample)

                # ç»Ÿä¸€ä¸º 2D array
                sv = raw[0] if isinstance(raw, list) else raw
                sv = np.array(sv)

                # expected_value æ ‡é‡åŒ–
                ev = explainer.expected_value
                base_val = float(ev[0] if hasattr(ev, '__len__') else ev)

                print(f"  âœ“ TreeExplainer æˆåŠŸ (æ ·æœ¬æ•°: {len(X_sample)})")

            except Exception as e:
                print(f"  âœ— TreeExplainer å¤±è´¥: {e}")
                # é™çº§åˆ° PermutationExplainer
                try:
                    print("  â†’ é™çº§åˆ° PermutationExplainer...")
                    bg = shap.sample(X_tr, min(50, len(X_tr)))
                    explainer = shap.PermutationExplainer(model.predict, bg)
                    X_sample  = X_te.iloc[:min(80, len(X_te))]
                    sv_obj    = explainer(X_sample)
                    sv        = np.array(sv_obj.values)
                    base_val  = float(sv_obj.base_values[0] if hasattr(sv_obj.base_values, '__len__') else sv_obj.base_values)
                    print(f"  âœ“ PermutationExplainer æˆåŠŸ (æ ·æœ¬æ•°: {len(X_sample)})")
                except Exception as e2:
                    print(f"  âœ— é™çº§ä¹Ÿå¤±è´¥: {e2}")
                    continue

        elif model_name in ['Ridge', 'Lasso', 'Adaptive Lasso', 'ElasticNet']:
            try:
                explainer = shap.LinearExplainer(
                    model, X_tr,
                    feature_perturbation='interventional'
                )
                X_sample = X_te
                raw      = explainer.shap_values(X_sample)
                sv       = np.array(raw[0] if isinstance(raw, list) else raw)

                ev = explainer.expected_value
                base_val = float(ev[0] if hasattr(ev, '__len__') else ev)

                print(f"  âœ“ LinearExplainer æˆåŠŸ (æ ·æœ¬æ•°: {len(X_sample)})")

            except Exception as e:
                print(f"  âœ— LinearExplainer å¤±è´¥: {e}")
                continue

        elif model_name in ['SVM', 'KNN']:
            try:
                n_bg = min(20, len(X_tr))
                background = shap.kmeans(X_tr, n_bg)
                explainer  = shap.KernelExplainer(model.predict, background)

                n_explain = min(60, len(X_te))
                X_sample  = X_te.iloc[:n_explain]
                raw       = explainer.shap_values(X_sample, silent=True)
                sv        = np.array(raw[0] if isinstance(raw, list) else raw)

                ev = explainer.expected_value
                base_val = float(ev[0] if hasattr(ev, '__len__') else ev)

                print(f"  âœ“ KernelExplainer (kmeansèƒŒæ™¯={n_bg}) æˆåŠŸ (æ ·æœ¬æ•°: {n_explain})")

            except Exception as e:
                print(f"  âœ— KernelExplainer å¤±è´¥: {e}")
                continue

        # =====================================================================
        # Stacking â€” PermutationExplainer
        # =====================================================================
        elif model_name == 'Stacking':
            try:
                n_bg = min(30, len(X_tr))
                bg   = shap.sample(X_tr, n_bg)
                explainer = shap.PermutationExplainer(model.predict, bg)

                n_explain = min(60, len(X_te))
                X_sample  = X_te.iloc[:n_explain]
                sv_obj    = explainer(X_sample)
                sv        = np.array(sv_obj.values)
                base_val  = float(
                    sv_obj.base_values[0]
                    if hasattr(sv_obj.base_values, '__len__')
                                        else sv_obj.base_values
                )
                print(f"  âœ“ PermutationExplainer æˆåŠŸ (èƒŒæ™¯={n_bg}, è§£é‡Š={n_explain})")

            except Exception as e:
                print(f"  âœ— PermutationExplainer å¤±è´¥: {e}")
                continue

        else:
            # å°è¯•é€šç”¨ PermutationExplainer
            try:
                bg   = shap.sample(X_tr, min(20, len(X_tr)))
                explainer = shap.PermutationExplainer(model.predict, bg)
                n_explain = min(60, len(X_te))
                X_sample  = X_te.iloc[:n_explain]
                sv_obj    = explainer(X_sample)
                sv        = np.array(sv_obj.values)
                base_val  = float(
                    sv_obj.base_values[0]
                    if hasattr(sv_obj.base_values, '__len__')
                    else sv_obj.base_values
                )
                print(f"  âœ“ PermutationExplainer (é€šç”¨) æˆåŠŸ")
            except Exception as e:
                print(f"  âœ— é€šç”¨SHAPå¤±è´¥: {e}")
                continue

        # =====================================================================
        # åå¤„ç†ï¼šæ£€æŸ¥ç»´åº¦ã€è®¡ç®—ç»Ÿè®¡é‡
        # =====================================================================
        if sv is None or sv.ndim != 2:
            print(f"  âœ— SHAPå€¼ç»´åº¦å¼‚å¸¸ï¼Œè·³è¿‡ {model_name}")
            continue

        # å¯¹é½ç‰¹å¾å
        if hasattr(X_sample, 'columns'):
            feat_names_used = list(X_sample.columns)
        else:
            feat_names_used = feature_names[:sv.shape[1]]

        # ç»´åº¦å¯¹é½æ£€æŸ¥
        if sv.shape[1] != len(feat_names_used):
            n_min = min(sv.shape[1], len(feat_names_used))
            sv = sv[:, :n_min]
            feat_names_used = feat_names_used[:n_min]

        # è®¡ç®— mean |SHAP| å’Œæ–¹å‘
        mean_abs_shap   = np.abs(sv).mean(axis=0)
        mean_signed_shap= sv.mean(axis=0)

        shap_importance = pd.DataFrame({
            'Feature':           feat_names_used,
            'Mean_Abs_SHAP':     mean_abs_shap,
            'Mean_Signed_SHAP':  mean_signed_shap,
        }).sort_values('Mean_Abs_SHAP', ascending=False).reset_index(drop=True)

        shap_importance['Direction'] = shap_importance['Mean_Signed_SHAP'].apply(
            lambda x: 'æ­£å½±å“(â†‘)' if x >= 0 else 'è´Ÿå½±å“(â†“)'
        )

        shap_results[model_name] = {
            'explainer':          explainer,
            'shap_values':        sv,
            'X_sample':           X_sample,
            'base_value':         base_val,
            'importance':         shap_importance,
            'feature_names_used': feat_names_used
        }

        n_samp = len(X_sample) if hasattr(X_sample, '__len__') else '?'
        print(f"âœ“ SHAPè®¡ç®—å®Œæˆ | æ ·æœ¬æ•°: {n_samp} | ç‰¹å¾æ•°: {sv.shape[1]}")
        print("  Top 10 ç‰¹å¾ (å«å½±å“æ–¹å‘):")
        for _, row in shap_importance.head(10).iterrows():
            bar = 'â–ˆ' * int(row['Mean_Abs_SHAP'] / (mean_abs_shap.max()+1e-9) * 20)
            print(f"    {row['Feature']:<30} {row['Mean_Abs_SHAP']:.5f} {bar} {row['Direction']}")

    success = len(shap_results)
    total   = len(trained_models)
    print(f"\nSHAPåˆ†æå®Œæˆ: {success}/{total} ä¸ªæ¨¡å‹æˆåŠŸ")
    return shap_results
# ==================== 7. å¯è§†åŒ–å‡½æ•° ====================
def create_visualizations(results, importance_results, shap_results, 
                         feature_names, y_test):
    """åˆ›å»ºæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨"""
    
    print("\n" + "=" * 100)
    print("æ­¥éª¤ 5: ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    print("=" * 100)
    
    # 7.1 æ¨¡å‹æ€§èƒ½å¯¹æ¯”ï¼ˆå¢å¼ºç‰ˆï¼‰
    print("\nç”Ÿæˆæ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾...")
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    
    model_names = list(results.keys())
    train_r2 = [results[m]['train_r2'] for m in model_names]
    test_r2 = [results[m]['test_r2'] for m in model_names]
    test_rmse = [results[m]['test_rmse'] for m in model_names]
    test_mae = [results[m]['test_mae'] for m in model_names]
    test_mape = [results[m]['test_mape'] for m in model_names]
    cv_means = [results[m]['cv_r2_mean'] for m in model_names]
    cv_stds = [results[m]['cv_r2_std'] for m in model_names]
    
    # RÂ² å¯¹æ¯”
    x = np.arange(len(model_names))
    width = 0.35
    axes[0, 0].bar(x - width/2, train_r2, width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')
    axes[0, 0].bar(x + width/2, test_r2, width, label='æµ‹è¯•é›†', alpha=0.8, color='coral')
    axes[0, 0].set_xlabel('æ¨¡å‹', fontsize=11)
    axes[0, 0].set_ylabel('RÂ² åˆ†æ•°', fontsize=11)
    axes[0, 0].set_title('æ¨¡å‹RÂ²æ€§èƒ½å¯¹æ¯”', fontsize=13, fontweight='bold')
    axes[0, 0].set_xticks(x)
    axes[0, 0].set_xticklabels(model_names, rotation=45, ha='right', fontsize=9)
    axes[0, 0].legend(fontsize=10)
    axes[0, 0].grid(axis='y', alpha=0.3)
    axes[0, 0].axhline(y=0.8, color='green', linestyle='--', alpha=0.5, label='ä¼˜ç§€çº¿')
    
    # RMSE å¯¹æ¯”
    colors = plt.cm.viridis(np.linspace(0, 1, len(model_names)))
    bars = axes[0, 1].bar(model_names, test_rmse, alpha=0.8, color=colors)
    axes[0, 1].set_xlabel('æ¨¡å‹', fontsize=11)
    axes[0, 1].set_ylabel('RMSE', fontsize=11)
    axes[0, 1].set_title('æ¨¡å‹RMSEå¯¹æ¯” (æµ‹è¯•é›†)', fontsize=13, fontweight='bold')
    axes[0, 1].set_xticklabels(model_names, rotation=45, ha='right', fontsize=9)
    axes[0, 1].grid(axis='y', alpha=0.3)
    for bar in bars:
        height = bar.get_height()
        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.2f}', ha='center', va='bottom', fontsize=8)
    
    # MAE å¯¹æ¯”
    bars = axes[0, 2].bar(model_names, test_mae, alpha=0.8, color='lightgreen')
    axes[0, 2].set_xlabel('æ¨¡å‹', fontsize=11)
    axes[0, 2].set_ylabel('MAE', fontsize=11)
    axes[0, 2].set_title('æ¨¡å‹MAEå¯¹æ¯” (æµ‹è¯•é›†)', fontsize=13, fontweight='bold')
    axes[0, 2].set_xticklabels(model_names, rotation=45, ha='right', fontsize=9)
    axes[0, 2].grid(axis='y', alpha=0.3)
    for bar in bars:
        height = bar.get_height()
        axes[0, 2].text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.2f}', ha='center', va='bottom', fontsize=8)
    
    # äº¤å‰éªŒè¯RÂ²
    bars = axes[1, 0].bar(model_names, cv_means, yerr=cv_stds, alpha=0.8, 
                          color='skyblue', capsize=5, error_kw={'linewidth': 2})
    axes[1, 0].set_xlabel('æ¨¡å‹', fontsize=11)
    axes[1, 0].set_ylabel('äº¤å‰éªŒè¯ RÂ²', fontsize=11)
    axes[1, 0].set_title('10æŠ˜äº¤å‰éªŒè¯RÂ²å¯¹æ¯”', fontsize=13, fontweight='bold')
    axes[1, 0].set_xticklabels(model_names, rotation=45, ha='right', fontsize=9)
    axes[1, 0].grid(axis='y', alpha=0.3)
    
    # MAPE å¯¹æ¯”
    bars = axes[1, 1].bar(model_names, test_mape, alpha=0.8, color='salmon')
    axes[1, 1].set_xlabel('æ¨¡å‹', fontsize=11)
    axes[1, 1].set_ylabel('MAPE (%)', fontsize=11)
    axes[1, 1].set_title('æ¨¡å‹MAPEå¯¹æ¯” (æµ‹è¯•é›†)', fontsize=13, fontweight='bold')
    axes[1, 1].set_xticklabels(model_names, rotation=45, ha='right', fontsize=9)
    axes[1, 1].grid(axis='y', alpha=0.3)
    for bar in bars:
        height = bar.get_height()
        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.1f}%', ha='center', va='bottom', fontsize=8)
    
    # è¿‡æ‹Ÿåˆåˆ†æ
    overfit_gaps = [train_r2[i] - test_r2[i] for i in range(len(model_names))]
    colors_overfit = ['red' if gap > 0.15 else 'orange' if gap > 0.10 else 'green' 
                      for gap in overfit_gaps]
    bars = axes[1, 2].bar(model_names, overfit_gaps, alpha=0.8, color=colors_overfit)
    axes[1, 2].set_xlabel('æ¨¡å‹', fontsize=11)
    axes[1, 2].set_ylabel('è®­ç»ƒé›†RÂ² - æµ‹è¯•é›†RÂ²', fontsize=11)
    axes[1, 2].set_title('è¿‡æ‹Ÿåˆåˆ†æ', fontsize=13, fontweight='bold')
    axes[1, 2].set_xticklabels(model_names, rotation=45, ha='right', fontsize=9)
    axes[1, 2].axhline(y=0.10, color='orange', linestyle='--', alpha=0.5, label='è½»å¾®è¿‡æ‹Ÿåˆçº¿')
    axes[1, 2].axhline(y=0.15, color='red', linestyle='--', alpha=0.5, label='ä¸¥é‡è¿‡æ‹Ÿåˆçº¿')
    axes[1, 2].legend(fontsize=8)
    axes[1, 2].grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(out_path('model_performance_comparison.png'), dpi=300, bbox_inches='tight')
    print("âœ“ ä¿å­˜: model_performance_comparison.png")
    plt.close()
    
    # 7.2 é¢„æµ‹å€¼ vs çœŸå®å€¼
    print("ç”Ÿæˆé¢„æµ‹å€¼vsçœŸå®å€¼æ•£ç‚¹å›¾...")
    n_models = len(model_names)
    n_cols = 3
    n_rows = (n_models + n_cols - 1) // n_cols
    
    fig_height = max(6, min(6*n_rows, 30))
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, fig_height))
    if n_models == 1:
        axes = np.array([axes])
    else:
        axes = axes.flatten()
    
    for idx, model_name in enumerate(model_names):
        y_pred = results[model_name]['y_pred_test']
        r2 = results[model_name]['test_r2']
        rmse = results[model_name]['test_rmse']
        mae = results[model_name]['test_mae']
        
        # æ•£ç‚¹å›¾
        axes[idx].scatter(y_test, y_pred, alpha=0.6, s=30, c='steelblue', edgecolors='black', linewidth=0.5)
        
        # ç†æƒ³é¢„æµ‹çº¿
        min_val = min(y_test.min(), y_pred.min())
        max_val = max(y_test.max(), y_pred.max())
        axes[idx].plot([min_val, max_val], [min_val, max_val], 
                       'r--', lw=2, label='ç†æƒ³é¢„æµ‹çº¿', alpha=0.8)
        
        # æ·»åŠ æ‹Ÿåˆçº¿
        z = np.polyfit(y_test, y_pred, 1)
        p = np.poly1d(z)
        axes[idx].plot(y_test.sort_values(), p(y_test.sort_values()), 
                      "g-", alpha=0.5, linewidth=2, label='æ‹Ÿåˆçº¿')
        
        axes[idx].set_xlabel('çœŸå®å€¼', fontsize=11)
        axes[idx].set_ylabel('é¢„æµ‹å€¼', fontsize=11)
        axes[idx].set_title(f'{model_name}\nRÂ²={r2:.4f}, RMSE={rmse:.2f}, MAE={mae:.2f}', 
                           fontsize=11, fontweight='bold')
        axes[idx].legend(fontsize=9)
        axes[idx].grid(alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        textstr = f'æ ·æœ¬æ•°: {len(y_test)}\nç›¸å…³ç³»æ•°: {np.corrcoef(y_test, y_pred)[0,1]:.4f}'
        axes[idx].text(0.05, 0.95, textstr, transform=axes[idx].transAxes,
                      fontsize=9, verticalalignment='top',
                      bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(len(model_names), len(axes)):
        axes[idx].axis('off')
    
    plt.tight_layout()
    plt.savefig(out_path('prediction_vs_actual.png'), dpi=300, bbox_inches='tight')
    print("âœ“ ä¿å­˜: prediction_vs_actual.png")
    plt.close()
    
    # 7.3 æ®‹å·®åˆ†æå›¾
    print("ç”Ÿæˆæ®‹å·®åˆ†æå›¾...")
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, fig_height))
    if n_models == 1:
        axes = np.array([axes])
    else:
        axes = axes.flatten()
    
    for idx, model_name in enumerate(model_names):
        y_pred = results[model_name]['y_pred_test']
        residuals = y_test - y_pred
        
        # æ®‹å·®æ•£ç‚¹å›¾
        axes[idx].scatter(y_pred, residuals, alpha=0.6, s=30, c='purple', edgecolors='black', linewidth=0.5)
        axes[idx].axhline(y=0, color='r', linestyle='--', lw=2)
        axes[idx].set_xlabel('é¢„æµ‹å€¼', fontsize=11)
        axes[idx].set_ylabel('æ®‹å·®', fontsize=11)
        axes[idx].set_title(f'{model_name} - æ®‹å·®åˆ†æ', fontsize=11, fontweight='bold')
        axes[idx].grid(alpha=0.3)
        
        # æ·»åŠ æ®‹å·®ç»Ÿè®¡ä¿¡æ¯
        textstr = f'æ®‹å·®å‡å€¼: {residuals.mean():.4f}\næ®‹å·®æ ‡å‡†å·®: {residuals.std():.4f}'
        axes[idx].text(0.05, 0.95, textstr, transform=axes[idx].transAxes,
                      fontsize=9, verticalalignment='top',
                      bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))
    
    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(len(model_names), len(axes)):
        axes[idx].axis('off')
    
    plt.tight_layout()
    plt.savefig(out_path('residual_analysis.png'), dpi=300, bbox_inches='tight')
    print("âœ“ ä¿å­˜: residual_analysis.png")
    plt.close()
    
    # 7.4 ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
    if importance_results:
        print("ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾...")
        n_importance = len(importance_results)
        n_cols = 3
        n_rows = (n_importance + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 6*n_rows))
        if n_importance == 1:
            axes = np.array([axes])
        else:
            axes = axes.flatten()
        
        for idx, (model_name, importance_df) in enumerate(importance_results.items()):
            if importance_df is not None:
                top_features = importance_df.head(15)
                
                # æ°´å¹³æ¡å½¢å›¾
                y_pos = np.arange(len(top_features))
                colors_bar = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(top_features)))
                
                axes[idx].barh(y_pos, top_features.values, color=colors_bar, alpha=0.8)
                axes[idx].set_yticks(y_pos)
                axes[idx].set_yticklabels(top_features.index, fontsize=9)
                axes[idx].set_xlabel('é‡è¦æ€§', fontsize=11)
                axes[idx].set_title(f'{model_name} - Top 15 ç‰¹å¾', fontsize=12, fontweight='bold')
                axes[idx].invert_yaxis()
                axes[idx].grid(axis='x', alpha=0.3)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, v in enumerate(top_features.values):
                    axes[idx].text(v, i, f' {v:.4f}', va='center', fontsize=8)
        
        # éšè—å¤šä½™çš„å­å›¾
        for idx in range(len(importance_results), len(axes)):
            axes[idx].axis('off')
        
        plt.tight_layout()
        plt.savefig(out_path('feature_importance.png'), dpi=300, bbox_inches='tight')
        print("âœ“ ä¿å­˜: feature_importance.png")
        plt.close()
    
    # 7.5 ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾ï¼ˆè·¨æ¨¡å‹å¯¹æ¯”ï¼‰
    if importance_results and len(importance_results) > 1:
        print("ç”Ÿæˆç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾...")
        
        # åˆ›å»ºç‰¹å¾é‡è¦æ€§çŸ©é˜µ
        all_features = set()
        for imp_df in importance_results.values():
            if imp_df is not None:
                all_features.update(imp_df.index.tolist())
        
        importance_matrix = pd.DataFrame(index=sorted(all_features), 
                                        columns=importance_results.keys())
        
        for model_name, imp_df in importance_results.items():
            if imp_df is not None:
                for feature, importance in imp_df.items():
                    importance_matrix.loc[feature, model_name] = importance
        
        importance_matrix = importance_matrix.fillna(0)
        
        # æ ‡å‡†åŒ–æ¯åˆ—ï¼ˆæ¯ä¸ªæ¨¡å‹ï¼‰
        importance_matrix_norm = importance_matrix.div(importance_matrix.max(axis=0), axis=1)
        
        # é€‰æ‹©Topç‰¹å¾
        top_features_overall = importance_matrix_norm.sum(axis=1).nlargest(20).index
        
        plt.figure(figsize=(14, 10))
        sns.heatmap(importance_matrix_norm.loc[top_features_overall], 
                   annot=True, fmt='.3f', cmap='YlOrRd', 
                   cbar_kws={'label': 'æ ‡å‡†åŒ–é‡è¦æ€§'},
                   linewidths=0.5)
        plt.title('ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾ (Top 20ç‰¹å¾, è·¨æ¨¡å‹å¯¹æ¯”)', 
                 fontsize=14, fontweight='bold', pad=20)
        plt.xlabel('æ¨¡å‹', fontsize=12)
        plt.ylabel('ç‰¹å¾', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.savefig(out_path('feature_importance_heatmap.png'), dpi=300, bbox_inches='tight')
        print("âœ“ ä¿å­˜: feature_importance_heatmap.png")
        plt.close()
    
    # 7.6 SHAPå¯è§†åŒ–
    if shap_results:
        print("ç”ŸæˆSHAPå¯è§†åŒ–å›¾ (å¢å¼ºç‰ˆ)...")
        
        # æ‰¾å‡ºæœ€ä¼˜çš„æ ‘æ¨¡å‹ï¼ˆç”¨äºä¾èµ–å›¾ï¼‰
        tree_models_in_shap = [m for m in shap_results 
                               if m in ['Random Forest','XGBoost','Gradient Boosting',
                                        'Extra Trees','LightGBM']]
        best_tree_for_shap = None
        if tree_models_in_shap and results:
            best_tree_for_shap = max(
                tree_models_in_shap,
                key=lambda m: results.get(m, {}).get('test_r2', -999)
            )
        
        for model_name, shap_data in shap_results.items():
            try:
                sv       = shap_data['shap_values']
                X_samp   = shap_data['X_sample']
                feat_names_used = shap_data.get('feature_names_used', feature_names)
                base_val = shap_data['base_value']
                
                # --- (a) SHAP Summary Plotï¼ˆèœ‚ç¾¤å›¾ï¼‰---
                plt.figure(figsize=(12, 8))
                shap.summary_plot(sv, X_samp, feature_names=feat_names_used,
                                  show=False, max_display=18)
                plt.title(f'{model_name} â€” SHAP Summary Plot (èœ‚ç¾¤å›¾)',
                         fontsize=13, fontweight='bold', pad=15)
                plt.tight_layout()
                plt.savefig(out_path(f'shap_summary_{model_name.replace(" ", "_")}.png'),
                           dpi=300, bbox_inches='tight')
                print(f"âœ“ shap_summary_{model_name.replace(' ', '_')}.png")
                plt.close()
                
                # --- (b) SHAP Bar Plotï¼ˆå¸¦æ­£è´Ÿæ–¹å‘é¢œè‰²ï¼‰---
                imp_df = shap_data['importance']
                top_n = min(18, len(imp_df))
                top_imp = imp_df.head(top_n)
                
                fig, ax = plt.subplots(figsize=(11, 8))
                bar_colors = ['#e74c3c' if d == 'æ­£å½±å“(â†‘)' else '#3498db'
                              for d in top_imp['Direction']]
                y_pos = np.arange(top_n)
                bars = ax.barh(y_pos, top_imp['Mean_Abs_SHAP'], color=bar_colors, alpha=0.85)
                ax.set_yticks(y_pos)
                ax.set_yticklabels(top_imp['Feature'], fontsize=10)
                ax.invert_yaxis()
                ax.set_xlabel('mean(|SHAP value|)', fontsize=12)
                ax.set_title(f'{model_name} â€” SHAP Feature Importance (çº¢=æ­£å½±å“, è“=è´Ÿå½±å“)',
                            fontsize=12, fontweight='bold')
                ax.grid(axis='x', alpha=0.3)
                for bar, val in zip(bars, top_imp['Mean_Abs_SHAP']):
                    ax.text(bar.get_width() + bar.get_width()*0.01, bar.get_y()+bar.get_height()/2,
                           f'{val:.4f}', va='center', fontsize=8)
                # å›¾ä¾‹
                from matplotlib.patches import Patch
                legend_elems = [Patch(facecolor='#e74c3c', label='æ­£å½±å“(å¢å¤§PM)'),
                                Patch(facecolor='#3498db', label='è´Ÿå½±å“(å‡å°PM)')]
                ax.legend(handles=legend_elems, loc='lower right', fontsize=10)
                plt.tight_layout()
                plt.savefig(out_path(f'shap_bar_{model_name.replace(" ", "_")}.png'),
                           dpi=300, bbox_inches='tight')
                print(f"âœ“ shap_bar_{model_name.replace(' ', '_')}.png")
                plt.close()
                
                # --- (c) SHAP Waterfall Plotï¼ˆæœ€é«˜é¢„æµ‹å€¼æ ·æœ¬ï¼‰---
                try:
                    n_sv = sv.shape[0]
                    approx_pred = sv.sum(axis=1) + base_val
                    highest_idx = int(np.argmax(approx_pred))
                    
                    if hasattr(X_samp, 'iloc'):
                        sample_data = X_samp.iloc[highest_idx].values
                    else:
                        sample_data = X_samp[highest_idx]
                    
                    plt.figure(figsize=(11, 8))
                    shap.waterfall_plot(
                        shap.Explanation(
                            values=sv[highest_idx],
                            base_values=base_val,
                            data=sample_data,
                            feature_names=feat_names_used
                        ),
                        show=False, max_display=15
                    )
                    plt.title(f'{model_name} â€” SHAP Waterfall (é¢„æµ‹å€¼æœ€é«˜æ ·æœ¬)',
                             fontsize=12, fontweight='bold')
                    plt.tight_layout()
                    plt.savefig(out_path(f'shap_waterfall_{model_name.replace(" ", "_")}.png'),
                               dpi=300, bbox_inches='tight')
                    print(f"âœ“ shap_waterfall_{model_name.replace(' ', '_')}.png")
                    plt.close()
                except Exception as ew:
                    print(f"  Waterfallå›¾è·³è¿‡: {ew}")
                
                                # --- (d) SHAP ä¾èµ–å›¾ï¼ˆTop 10ç‰¹å¾ï¼Œä»…æœ€ä¼˜æ ‘æ¨¡å‹ï¼‰---
                if model_name == best_tree_for_shap:
                    top10_features = imp_df['Feature'].head(10).tolist()
                    fig, axes_dep = plt.subplots(2, 2, figsize=(16, 12))
                    axes_dep = axes_dep.flatten()
                    
                    for fi, feat in enumerate(top10_features):
                        if feat in feat_names_used:
                            feat_idx = feat_names_used.index(feat)
                            ax_dep = axes_dep[fi]
                            
                            # è·å–è¯¥ç‰¹å¾çš„ç‰¹å¾å€¼å’ŒSHAPå€¼
                            feat_vals = X_samp[feat].values if hasattr(X_samp,'columns') else X_samp[:, feat_idx]
                            shap_vals_feat = sv[:, feat_idx]
                            
                            # ç”¨Ground_PMä½œä¸ºäº¤äº’è‰²å½©å˜é‡ï¼ˆè‹¥å­˜åœ¨ï¼‰
                            color_feat = 'Ground_PM' if 'Ground_PM' in feat_names_used else None
                            if color_feat and color_feat != feat:
                                color_idx = feat_names_used.index(color_feat)
                                c_vals = X_samp[color_feat].values if hasattr(X_samp,'columns') else X_samp[:, color_idx]
                                sc = ax_dep.scatter(feat_vals, shap_vals_feat,
                                                   c=c_vals, cmap='RdYlBu_r', alpha=0.7, s=20)
                                plt.colorbar(sc, ax=ax_dep, label=color_feat)
                            else:
                                ax_dep.scatter(feat_vals, shap_vals_feat,
                                             alpha=0.6, s=20, c='steelblue')
                            
                            ax_dep.axhline(0, color='gray', linestyle='--', lw=1)
                            ax_dep.set_xlabel(feat, fontsize=11)
                            ax_dep.set_ylabel('SHAP value', fontsize=11)
                            ax_dep.set_title(f'ä¾èµ–å›¾: {feat}', fontsize=12, fontweight='bold')
                            ax_dep.grid(alpha=0.3)
                    
                    plt.suptitle(f'{model_name} â€” SHAPä¾èµ–å›¾',
                                fontsize=14, fontweight='bold', y=1.01)
                    plt.tight_layout()
                    plt.savefig(out_path(f'shap_dependence_{model_name.replace(" ", "_")}.png'),
                               dpi=300, bbox_inches='tight')
                    print(f"âœ“ shap_dependence_{model_name.replace(' ', '_')}.png")
                    plt.close()
                    
            except Exception as e:
                print(f"âš ï¸  {model_name} SHAPå¯è§†åŒ–å¤±è´¥: {str(e)}")
                continue
        
        # --- (e) åŒæœ€ä¼˜æ¨¡å‹ SHAP å¯¹æ¯”å›¾ ---
        if len(shap_results) >= 2 and results:
            print("ç”ŸæˆåŒæ¨¡å‹SHAPå¯¹æ¯”å›¾...")
            sorted_by_r2 = sorted(
                [m for m in shap_results if m in results],
                key=lambda m: results[m]['test_r2'], reverse=True
            )
            top2 = sorted_by_r2[:2]
            
            try:
                fig, axes2 = plt.subplots(1, 2, figsize=(22, 9))
                for ai, mn in enumerate(top2):
                    shap_importance_matrix = pd.DataFrame()
                    for mn2, sd2 in shap_results.items():
                        shap_importance_matrix[mn2] = (
                            sd2['importance'].set_index('Feature')['Mean_Abs_SHAP']
                        )
                    
                    top_feats_all = (shap_importance_matrix
                                    .fillna(0).sum(axis=1).nlargest(15).index.tolist())
                    
                    sd   = shap_results[mn]
                    imp  = sd['importance'].set_index('Feature')['Mean_Abs_SHAP']
                    vals = [imp.get(f, 0) for f in top_feats_all]
                    
                    # é‡æ–°æŸ¥æ–¹å‘
                    dir_map = dict(zip(sd['importance']['Feature'], sd['importance']['Direction']))
                    colors_bar = ['#e74c3c' if dir_map.get(f,'æ­£å½±å“(â†‘)')=='æ­£å½±å“(â†‘)' else '#3498db'
                                  for f in top_feats_all]
                    
                    y_p = np.arange(len(top_feats_all))
                    axes2[ai].barh(y_p, vals, color=colors_bar, alpha=0.85)
                    axes2[ai].set_yticks(y_p)
                    axes2[ai].set_yticklabels(top_feats_all, fontsize=9)
                    axes2[ai].invert_yaxis()
                    axes2[ai].set_xlabel('mean(|SHAP value|)', fontsize=11)
                    r2v = results[mn]['test_r2']
                    axes2[ai].set_title(f'{mn} (Test RÂ²={r2v:.4f})', fontsize=12, fontweight='bold')
                    axes2[ai].grid(axis='x', alpha=0.3)
                
                plt.suptitle('Top-2æ¨¡å‹ SHAPç‰¹å¾é‡è¦æ€§å¯¹æ¯” (çº¢=æ­£å½±å“, è“=è´Ÿå½±å“)',
                            fontsize=14, fontweight='bold')
                plt.tight_layout()
                plt.savefig(out_path('shap_top2_comparison.png'), dpi=300, bbox_inches='tight')
                print("âœ“ shap_top2_comparison.png")
                plt.close()
            except Exception as ec:
                print(f"  åŒæ¨¡å‹å¯¹æ¯”å›¾è·³è¿‡: {ec}")
        
        # --- (f) SHAPé‡è¦æ€§çƒ­åŠ›å›¾ï¼ˆè·¨æ¨¡å‹ï¼‰---
        print("ç”ŸæˆSHAPé‡è¦æ€§çƒ­åŠ›å›¾...")
        shap_importance_matrix = pd.DataFrame()
        for mn2, sd2 in shap_results.items():
            shap_importance_matrix[mn2] = (
                sd2['importance'].set_index('Feature')['Mean_Abs_SHAP']
            )
        
        if not shap_importance_matrix.empty:
            shap_importance_norm = shap_importance_matrix.fillna(0)
            shap_importance_norm = shap_importance_norm.div(
                shap_importance_norm.max(axis=0).replace(0, 1), axis=1
            )
            top_shap_features = shap_importance_norm.sum(axis=1).nlargest(20).index
            
            plt.figure(figsize=(14, 10))
            sns.heatmap(shap_importance_norm.loc[top_shap_features],
                       annot=True, fmt='.3f', cmap='Blues',
                       cbar_kws={'label': 'æ ‡å‡†åŒ–SHAPé‡è¦æ€§'},
                       linewidths=0.5)
            plt.title('SHAPé‡è¦æ€§çƒ­åŠ›å›¾ (Top 20ç‰¹å¾, è·¨æ¨¡å‹å¯¹æ¯”)',
                     fontsize=14, fontweight='bold', pad=20)
            plt.xlabel('æ¨¡å‹', fontsize=12)
            plt.ylabel('ç‰¹å¾', fontsize=12)
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)
            plt.tight_layout()
            plt.savefig(out_path('shap_importance_heatmap.png'), dpi=300, bbox_inches='tight')
            print("âœ“ shap_importance_heatmap.png")
            plt.close()
    
    # 7.7 æ¨¡å‹æ’åé›·è¾¾å›¾
    print("ç”Ÿæˆæ¨¡å‹æ€§èƒ½é›·è¾¾å›¾...")
    
    # å‡†å¤‡æ•°æ®ï¼ˆæ ‡å‡†åŒ–åˆ°0-1ï¼‰
    metrics = {
        'RÂ²': test_r2,
        'RMSE': [1/(1+x) for x in test_rmse],  # è½¬æ¢ä¸ºè¶Šå¤§è¶Šå¥½
        'MAE': [1/(1+x) for x in test_mae],    # è½¬æ¢ä¸ºè¶Šå¤§è¶Šå¥½
        'CV RÂ²': cv_means,
        'æ³›åŒ–èƒ½åŠ›': [1-abs(train_r2[i]-test_r2[i]) for i in range(len(model_names))]
    }
    
    # æ ‡å‡†åŒ–
    for key in metrics:
        max_val = max(metrics[key])
        min_val = min(metrics[key])
        if max_val > min_val:
            metrics[key] = [(x-min_val)/(max_val-min_val) for x in metrics[key]]
    
    # åˆ›å»ºé›·è¾¾å›¾
    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
    angles += angles[:1]
    
    fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(projection='polar'))
    
    colors_radar = plt.cm.tab10(np.linspace(0, 1, len(model_names)))
    
    for idx, model_name in enumerate(model_names):
        values = [metrics[key][idx] for key in metrics.keys()]
        values += values[:1]
        
        ax.plot(angles, values, 'o-', linewidth=2, label=model_name, color=colors_radar[idx])
        ax.fill(angles, values, alpha=0.15, color=colors_radar[idx])
    
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(metrics.keys(), fontsize=11)
    ax.set_ylim(0, 1)
    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
    ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=9)
    ax.grid(True)
    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)
    plt.title('æ¨¡å‹ç»¼åˆæ€§èƒ½é›·è¾¾å›¾', fontsize=14, fontweight='bold', pad=30)
    plt.tight_layout()
    plt.savefig(out_path('model_radar_chart.png'), dpi=300, bbox_inches='tight')
    print("âœ“ ä¿å­˜: model_radar_chart.png")
    plt.close()

    # 7.8 è¿‡æ‹Ÿåˆè¯Šæ–­ä¸“é¡¹å›¾
    print("ç”Ÿæˆè¿‡æ‹Ÿåˆè¯Šæ–­å›¾...")
    gaps = [results[m]['train_r2'] - results[m]['test_r2'] for m in model_names]
    cv_r2 = [results[m]['cv_r2_mean'] for m in model_names]

    fig, axes_of = plt.subplots(1, 3, figsize=(22, 7))

    # (1) è®­ç»ƒ/æµ‹è¯•/CV RÂ² ä¸‰çº¿å¯¹æ¯”
    x = np.arange(len(model_names))
    w = 0.25
    axes_of[0].bar(x - w, train_r2, w, label='è®­ç»ƒé›†RÂ²',  color='#3498db', alpha=0.85)
    axes_of[0].bar(x,     test_r2,  w, label='æµ‹è¯•é›†RÂ²',  color='#e74c3c', alpha=0.85)
    axes_of[0].bar(x + w, cv_r2,    w, label='CV RÂ²(å‡å€¼)', color='#2ecc71', alpha=0.85)
    axes_of[0].set_xticks(x)
    axes_of[0].set_xticklabels(model_names, rotation=45, ha='right', fontsize=8)
    axes_of[0].set_ylabel('RÂ²', fontsize=11)
    axes_of[0].set_title('è®­ç»ƒ/æµ‹è¯•/CV RÂ² ä¸‰å‘å¯¹æ¯”', fontsize=12, fontweight='bold')
    axes_of[0].legend(fontsize=9)
    axes_of[0].axhline(0.8, color='gray', ls='--', lw=1, alpha=0.5)
    axes_of[0].grid(axis='y', alpha=0.3)

    # (2) è¿‡æ‹Ÿåˆå·®è·æ¡å½¢å›¾ï¼ˆé¢œè‰²ç¼–ç ï¼‰
    gap_colors = []
    for g in gaps:
        if   g > 0.20: gap_colors.append('#c0392b')   # æ·±çº¢ï¼šä¸¥é‡
        elif g > 0.12: gap_colors.append('#e67e22')   # æ©™ï¼šæ˜æ˜¾
        elif g > 0.05: gap_colors.append('#f1c40f')   # é»„ï¼šè½»å¾®
        else:          gap_colors.append('#27ae60')   # ç»¿ï¼šè‰¯å¥½
    bars_gap = axes_of[1].bar(model_names, gaps, color=gap_colors, alpha=0.85, edgecolor='white')
    axes_of[1].axhline(0.20, color='#c0392b', ls='--', lw=1.5, label='ä¸¥é‡é˜ˆå€¼(0.20)')
    axes_of[1].axhline(0.12, color='#e67e22', ls='--', lw=1.5, label='æ˜æ˜¾é˜ˆå€¼(0.12)')
    axes_of[1].axhline(0.05, color='#f1c40f', ls='--', lw=1.5, label='è½»å¾®é˜ˆå€¼(0.05)')
    for bar, g in zip(bars_gap, gaps):
        axes_of[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.003,
                        f'{g:+.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
    axes_of[1].set_xticklabels(model_names, rotation=45, ha='right', fontsize=8)
    axes_of[1].set_ylabel('è¿‡æ‹Ÿåˆå·®è·ï¼ˆè®­ç»ƒRÂ² - æµ‹è¯•RÂ²ï¼‰', fontsize=11)
    axes_of[1].set_title('å„æ¨¡å‹è¿‡æ‹Ÿåˆå·®è·ï¼ˆé¢œè‰²=ä¸¥é‡ç¨‹åº¦ï¼‰', fontsize=12, fontweight='bold')
    axes_of[1].grid(axis='y', alpha=0.3)
    # å›¾ä¾‹è¡¥ä¸
    from matplotlib.patches import Patch
    legend_patches = [
        Patch(color='#27ae60', label='ğŸŸ¢ æ³›åŒ–è‰¯å¥½ (â‰¤0.05)'),
        Patch(color='#f1c40f', label='ğŸŸ¡ è½»å¾®è¿‡æ‹Ÿåˆ (0.05-0.12)'),
        Patch(color='#e67e22', label='ğŸŸ  æ˜æ˜¾è¿‡æ‹Ÿåˆ (0.12-0.20)'),
        Patch(color='#c0392b', label='ğŸ”´ ä¸¥é‡è¿‡æ‹Ÿåˆ (>0.20)')
    ]
    axes_of[1].legend(handles=legend_patches, fontsize=8, loc='upper left')

    # (3) æµ‹è¯•RÂ² vs CV RÂ² æ•£ç‚¹å›¾ï¼ˆç†æƒ³=å¯¹è§’çº¿ï¼‰
    axes_of[2].scatter(cv_r2, test_r2, c=gap_colors, s=120, edgecolors='black', linewidth=0.8, zorder=5)
    min_v = min(min(cv_r2), min(test_r2)) - 0.05
    max_v = max(max(cv_r2), max(test_r2)) + 0.05
    axes_of[2].plot([min_v, max_v], [min_v, max_v], 'k--', lw=1.5, alpha=0.5, label='ç†æƒ³çº¿(CV=Test)')
    for mn2, cx, ty in zip(model_names, cv_r2, test_r2):
        axes_of[2].annotate(mn2, (cx, ty), textcoords='offset points',
                            xytext=(4, 4), fontsize=7)
    axes_of[2].set_xlabel('CV RÂ²ï¼ˆäº¤å‰éªŒè¯å‡å€¼ï¼‰', fontsize=11)
    axes_of[2].set_ylabel('æµ‹è¯•é›†RÂ²', fontsize=11)
    axes_of[2].set_title('CV RÂ² vs æµ‹è¯•é›†RÂ²ï¼ˆåç¦»å¯¹è§’çº¿=æ³›åŒ–å·®ï¼‰', fontsize=12, fontweight='bold')
    axes_of[2].legend(fontsize=9)
    axes_of[2].grid(alpha=0.3)

    plt.suptitle('æ¨¡å‹è¿‡æ‹Ÿåˆè¯Šæ–­ç»¼åˆåˆ†æ', fontsize=15, fontweight='bold', y=1.01)
    plt.tight_layout()
    plt.savefig(out_path('overfitting_diagnosis.png'), dpi=300, bbox_inches='tight')
    print("âœ“ ä¿å­˜: overfitting_diagnosis.png")
    plt.close()

    # 7.9 è¯¯å·®åˆ†å¸ƒç®±çº¿å›¾
    print("ç”Ÿæˆè¯¯å·®åˆ†å¸ƒç®±çº¿å›¾...")
    
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    
    # ç»å¯¹è¯¯å·®
    abs_errors = [np.abs(y_test - results[m]['y_pred_test']) for m in model_names]
    bp1 = axes[0].boxplot(abs_errors, labels=model_names, patch_artist=True,
                          showmeans=True, meanline=True)
    for patch, color in zip(bp1['boxes'], colors_radar):
        patch.set_facecolor(color)
        patch.set_alpha(0.6)
    axes[0].set_xlabel('æ¨¡å‹', fontsize=12)
    axes[0].set_ylabel('ç»å¯¹è¯¯å·®', fontsize=12)
    axes[0].set_title('æ¨¡å‹ç»å¯¹è¯¯å·®åˆ†å¸ƒ', fontsize=13, fontweight='bold')
    axes[0].grid(axis='y', alpha=0.3)
    axes[0].tick_params(axis='x', rotation=45)
    
    # ç›¸å¯¹è¯¯å·®ç™¾åˆ†æ¯”
    rel_errors = [np.abs((y_test - results[m]['y_pred_test']) / y_test) * 100 
                  for m in model_names]
    bp2 = axes[1].boxplot(rel_errors, labels=model_names, patch_artist=True,
                          showmeans=True, meanline=True)
    for patch, color in zip(bp2['boxes'], colors_radar):
        patch.set_facecolor(color)
        patch.set_alpha(0.6)
    axes[1].set_xlabel('æ¨¡å‹', fontsize=12)
    axes[1].set_ylabel('ç›¸å¯¹è¯¯å·® (%)', fontsize=12)
    axes[1].set_title('æ¨¡å‹ç›¸å¯¹è¯¯å·®åˆ†å¸ƒ', fontsize=13, fontweight='bold')
    axes[1].grid(axis='y', alpha=0.3)
    axes[1].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.savefig(out_path('error_distribution.png'), dpi=300, bbox_inches='tight')
    print("âœ“ ä¿å­˜: error_distribution.png")
    plt.close()
    
    print("\næ‰€æœ‰å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
    # ==================== 8. ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š ====================
def generate_report(results, importance_results, shap_results, feature_names):
    """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š"""
    
    print("\n" + "=" * 100)
    print("æ­¥éª¤ 6: ç”Ÿæˆåˆ†ææŠ¥å‘Š")
    print("=" * 100)
    
    # æå‰åˆå§‹åŒ–è·¨æ¨¡å‹ç»Ÿè®¡å˜é‡
    all_top5_features = []
    all_top10_features = []
    all_shap_top5 = []
    all_shap_top10 = []

    report = []
    report.append("=" * 120)
    report.append("åœ°é“é¢—ç²’ç‰©æµ“åº¦é¢„æµ‹æ¨¡å‹åˆ†ææŠ¥å‘Š")
    report.append("=" * 120)
    report.append(f"\nç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("\n")
    
    # 1. æ•°æ®æ¦‚å†µ
    report.append("ä¸€ã€æ•°æ®æ¦‚å†µ")
    report.append("-" * 120)
    report.append(f"ç‰¹å¾æ•°é‡: {len(feature_names)}")
    report.append(f"\nç‰¹å¾åˆ—è¡¨:")
    for i, feat in enumerate(feature_names, 1):
        report.append(f"  {i:2d}. {feat}")
    report.append(f"\nç›®æ ‡å˜é‡: Metro_PM")
    report.append(f"è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†æ¯”ä¾‹: 80% / 20%")
    report.append("\n")
    
    # 2. æ¨¡å‹æ€§èƒ½æ€»ç»“
    report.append("äºŒã€æ¨¡å‹æ€§èƒ½æ€»ç»“")
    report.append("-" * 120)
    
    # åˆ›å»ºæ€§èƒ½å¯¹æ¯”è¡¨
    performance_df = pd.DataFrame({
        'æ¨¡å‹': list(results.keys()),
        'è®­ç»ƒé›†RÂ²': [f"{results[m]['train_r2']:.4f}" for m in results.keys()],
        'æµ‹è¯•é›†RÂ²': [f"{results[m]['test_r2']:.4f}" for m in results.keys()],
        'æµ‹è¯•é›†RMSE': [f"{results[m]['test_rmse']:.4f}" for m in results.keys()],
        'æµ‹è¯•é›†MAE': [f"{results[m]['test_mae']:.4f}" for m in results.keys()],
        'æµ‹è¯•é›†MAPE': [f"{results[m]['test_mape']:.2f}%" for m in results.keys()],
        'äº¤å‰éªŒè¯RÂ²': [f"{results[m]['cv_r2_mean']:.4f}Â±{results[m]['cv_r2_std']:.4f}" 
                      for m in results.keys()]
    })
    
    report.append("\næ€§èƒ½æŒ‡æ ‡å¯¹æ¯”è¡¨:")
    report.append(performance_df.to_string(index=False))
    report.append("\n")
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    test_r2_values = [results[m]['test_r2'] for m in results.keys()]
    test_rmse_values = [results[m]['test_rmse'] for m in results.keys()]
    test_mae_values = [results[m]['test_mae'] for m in results.keys()]
    
    best_model_r2_idx = np.argmax(test_r2_values)
    best_model_rmse_idx = np.argmin(test_rmse_values)
    best_model_mae_idx = np.argmin(test_mae_values)
    
    best_model_r2 = list(results.keys())[best_model_r2_idx]
    best_model_rmse = list(results.keys())[best_model_rmse_idx]
    best_model_mae = list(results.keys())[best_model_mae_idx]
    
    report.append("æœ€ä½³æ¨¡å‹:")
    report.append(f"  â˜… æœ€é«˜RÂ²: {best_model_r2} (RÂ² = {test_r2_values[best_model_r2_idx]:.4f})")
    report.append(f"  â˜… æœ€ä½RMSE: {best_model_rmse} (RMSE = {test_rmse_values[best_model_rmse_idx]:.4f})")
    report.append(f"  â˜… æœ€ä½MAE: {best_model_mae} (MAE = {test_mae_values[best_model_mae_idx]:.4f})")
    report.append("\n")
    
    # æ¨¡å‹æ’å
    report.append("æ¨¡å‹ç»¼åˆæ’å (æŒ‰æµ‹è¯•é›†RÂ²):")
    sorted_models = sorted(results.items(), key=lambda x: x[1]['test_r2'], reverse=True)
    for rank, (model_name, model_results) in enumerate(sorted_models, 1):
        report.append(f"  {rank}. {model_name:<20} RÂ²={model_results['test_r2']:.4f}, "
                     f"RMSE={model_results['test_rmse']:.4f}, MAE={model_results['test_mae']:.4f}")
    report.append("\n")
    
    # 3. è¿‡æ‹Ÿåˆåˆ†æ
    report.append("ä¸‰ã€è¿‡æ‹Ÿåˆåˆ†æ")
    report.append("-" * 120)
    
    for model_name in results.keys():
        train_r2 = results[model_name]['train_r2']
        test_r2 = results[model_name]['test_r2']
        gap = train_r2 - test_r2
        
        if gap > 0.20:
            status = "ğŸ”´ ä¸¥é‡è¿‡æ‹Ÿåˆ"
            recommendation = "å»ºè®®: å¤§å¹…å¢åŠ æ­£åˆ™åŒ–å¼ºåº¦ã€å‡å°‘æ¨¡å‹å¤æ‚åº¦ã€å¢åŠ è®­ç»ƒæ•°æ®"
        elif gap > 0.12:
            status = "ğŸŸ  æ˜æ˜¾è¿‡æ‹Ÿåˆ"
            recommendation = "å»ºè®®: é€‚å½“å¢å¤§æ­£åˆ™åŒ–ã€é™ä½max_depthã€å¢å¤§min_samples_leaf"
        elif gap > 0.05:
            status = "ğŸŸ¡ è½»å¾®è¿‡æ‹Ÿåˆ"
            recommendation = "å»ºè®®: å¯æ¥å—èŒƒå›´ï¼Œå¯å¾®è°ƒæ­£åˆ™åŒ–å‚æ•°è¿›ä¸€æ­¥æ”¹å–„"
        elif gap < -0.05:
            status = "âš ï¸  æ¬ æ‹Ÿåˆ"
            recommendation = "å»ºè®®: å¢åŠ æ¨¡å‹å¤æ‚åº¦ã€æ·»åŠ æ›´å¤šç‰¹å¾ã€å‡å°‘æ­£åˆ™åŒ–"
        else:
            status = "ğŸŸ¢ æ³›åŒ–è‰¯å¥½"
            recommendation = "æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¼˜ç§€ï¼Œè®­ç»ƒ/æµ‹è¯•ä¸€è‡´"
        
        report.append(f"{model_name:<20} è®­ç»ƒRÂ²={train_r2:.4f}, æµ‹è¯•RÂ²={test_r2:.4f}, "
                     f"å·®è·={gap:+.4f} {status}")
        report.append(f"{'':20} {recommendation}")
    report.append("\n")
    
    # 4. ç‰¹å¾é‡è¦æ€§æ€»ç»“
    report.append("å››ã€ç‰¹å¾é‡è¦æ€§æ€»ç»“")
    report.append("-" * 120)
    
    if importance_results:
        from collections import Counter
        
        for model_name, importance_df in importance_results.items():
            if importance_df is not None:
                report.append(f"\n{model_name} - Top 10 é‡è¦ç‰¹å¾:")
                top_10 = importance_df.head(10)
                for rank, (idx, row) in enumerate(top_10.items(), 1):
                    report.append(f"  {rank:2d}. {idx:<30} {row:.6f}")
                
                all_top5_features.extend(importance_df.head(5).index.tolist())
                all_top10_features.extend(importance_df.head(10).index.tolist())
        
        # è·¨æ¨¡å‹ç‰¹å¾é‡è¦æ€§ç»Ÿè®¡
        if all_top5_features:
            report.append("\nè·¨æ¨¡å‹ç‰¹å¾é‡è¦æ€§ç»Ÿè®¡ (Top 5å‡ºç°é¢‘ç‡):")
            feature_counts_top5 = Counter(all_top5_features)
            for feature, count in feature_counts_top5.most_common(10):
                percentage = (count / len([imp for imp in importance_results.values() if imp is not None])) * 100
                report.append(f"  {feature:<30} å‡ºç°{count}æ¬¡ ({percentage:.1f}%çš„æ¨¡å‹)")
        
        if all_top10_features:
            report.append("\nè·¨æ¨¡å‹ç‰¹å¾é‡è¦æ€§ç»Ÿè®¡ (Top 10å‡ºç°é¢‘ç‡):")
            feature_counts_top10 = Counter(all_top10_features)
            for feature, count in feature_counts_top10.most_common(15):
                percentage = (count / len([imp for imp in importance_results.values() if imp is not None])) * 100
                report.append(f"  {feature:<30} å‡ºç°{count}æ¬¡ ({percentage:.1f}%çš„æ¨¡å‹)")
    
    report.append("\n")
    
    # 5. SHAPåˆ†ææ€»ç»“
    if shap_results:
        report.append("äº”ã€SHAPå€¼åˆ†ææ€»ç»“")
        report.append("-" * 120)
        
        for model_name, shap_data in shap_results.items():
            if 'importance' in shap_data:
                report.append(f"\n{model_name} - Top 10 SHAPé‡è¦ç‰¹å¾:")
                top_10_shap = shap_data['importance'].head(10)
                for rank, (idx, row) in enumerate(top_10_shap.iterrows(), 1):
                    report.append(f"  {rank:2d}. {row['Feature']:<30} {row['Mean_Abs_SHAP']:.6f} {row['Direction']}")
                
                all_shap_top5.extend(shap_data['importance'].head(5)['Feature'].tolist())
                all_shap_top10.extend(shap_data['importance'].head(10)['Feature'].tolist())
        
        # è·¨æ¨¡å‹SHAPé‡è¦æ€§ç»Ÿè®¡
        if all_shap_top5:
            from collections import Counter
            report.append("\nè·¨æ¨¡å‹SHAPé‡è¦æ€§ç»Ÿè®¡ (Top 5å‡ºç°é¢‘ç‡):")
            shap_counts_top5 = Counter(all_shap_top5)
            for feature, count in shap_counts_top5.most_common(10):
                percentage = (count / len(shap_results)) * 100
                report.append(f"  {feature:<30} å‡ºç°{count}æ¬¡ ({percentage:.1f}%çš„æ¨¡å‹)")
            
            report.append("\nè·¨æ¨¡å‹SHAPé‡è¦æ€§ç»Ÿè®¡ (Top 10å‡ºç°é¢‘ç‡):")
            shap_counts_top10 = Counter(all_shap_top10)
            for feature, count in shap_counts_top10.most_common(15):
                percentage = (count / len(shap_results)) * 100
                report.append(f"  {feature:<30} å‡ºç°{count}æ¬¡ ({percentage:.1f}%çš„æ¨¡å‹)")
    
    report.append("\n")
    
    # 6. æœ€ä½³è¶…å‚æ•°é…ç½®
    report.append("å…­ã€æœ€ä½³è¶…å‚æ•°é…ç½®")
    report.append("-" * 120)
    
    for model_name in results.keys():
        report.append(f"\n{model_name}:")
        best_params = results[model_name]['best_params']
        for param, value in best_params.items():
            report.append(f"  {param:<30} {value}")
    
    report.append("\n")
    
    # 7. æ¨¡å‹æ€§èƒ½è¯„çº§
    report.append("ä¸ƒã€æ¨¡å‹æ€§èƒ½è¯„çº§")
    report.append("-" * 120)
    
    for model_name in results.keys():
        test_r2 = results[model_name]['test_r2']
        test_rmse = results[model_name]['test_rmse']
        test_mape = results[model_name]['test_mape']
        
        # RÂ²è¯„çº§
        if test_r2 >= 0.9:
            r2_grade = "A+ (ä¼˜ç§€)"
        elif test_r2 >= 0.8:
            r2_grade = "A  (è‰¯å¥½)"
        elif test_r2 >= 0.7:
            r2_grade = "B  (ä¸­ç­‰)"
        elif test_r2 >= 0.6:
            r2_grade = "C  (åŠæ ¼)"
        else:
            r2_grade = "D  (è¾ƒå·®)"
        
        # MAPEè¯„çº§
        if test_mape < 10:
            mape_grade = "A+ (ä¼˜ç§€)"
        elif test_mape < 20:
            mape_grade = "A  (è‰¯å¥½)"
        elif test_mape < 30:
            mape_grade = "B  (ä¸­ç­‰)"
        elif test_mape < 50:
            mape_grade = "C  (åŠæ ¼)"
        else:
            mape_grade = "D  (è¾ƒå·®)"
        
        report.append(f"\n{model_name}:")
        report.append(f"  RÂ²è¯„çº§:    {r2_grade}")
        report.append(f"  MAPEè¯„çº§:  {mape_grade}")
        report.append(f"  ç»¼åˆè¯„ä»·:  RÂ²={test_r2:.4f}, RMSE={test_rmse:.4f}, MAPE={test_mape:.2f}%")
    
    report.append("\n")
    
    # 8. å…³é”®å‘ç°
    report.append("å…«ã€å…³é”®å‘ç°")
    report.append("-" * 120)
    
    # 8.1 æœ€ä½³æ¨¡å‹åˆ†æ
    best_overall = sorted_models[0][0]
    best_r2 = sorted_models[0][1]['test_r2']
    best_rmse = sorted_models[0][1]['test_rmse']
    best_mape = sorted_models[0][1]['test_mape']
    
    report.append(f"\n1. æœ€ä½³é¢„æµ‹æ¨¡å‹: {best_overall}")
    report.append(f"   - æµ‹è¯•é›†RÂ²è¾¾åˆ° {best_r2:.4f}ï¼Œè¡¨æ˜æ¨¡å‹èƒ½å¤Ÿè§£é‡Š{best_r2*100:.2f}%çš„æ–¹å·®")
    report.append(f"   - RMSEä¸º {best_rmse:.4f}ï¼ŒMAEä¸º {sorted_models[0][1]['test_mae']:.4f}")
    report.append(f"   - MAPEä¸º {best_mape:.2f}%ï¼Œå¹³å‡é¢„æµ‹è¯¯å·®åœ¨å¯æ¥å—èŒƒå›´å†…")
    
    # 8.2 æ¨¡å‹å¯¹æ¯”åˆ†æ
    report.append("\n2. æ¨¡å‹ç±»å‹å¯¹æ¯”:")
    
    tree_models = ['Random Forest', 'XGBoost', 'Gradient Boosting', 'Extra Trees', 'LightGBM']
    linear_models = ['Ridge', 'Lasso', 'Adaptive Lasso', 'ElasticNet']
    other_models = ['KNN', 'SVM']
    
    tree_r2_list = [results[m]['test_r2'] for m in tree_models if m in results]
    linear_r2_list = [results[m]['test_r2'] for m in linear_models if m in results]
    other_r2_list = [results[m]['test_r2'] for m in other_models if m in results]
    
    tree_avg_r2 = np.mean(tree_r2_list) if tree_r2_list else 0
    linear_avg_r2 = np.mean(linear_r2_list) if linear_r2_list else 0
    other_avg_r2 = np.mean(other_r2_list) if other_r2_list else 0
    
    report.append(f"   - æ ‘æ¨¡å‹å¹³å‡RÂ²: {tree_avg_r2:.4f}")
    report.append(f"   - çº¿æ€§æ¨¡å‹å¹³å‡RÂ²: {linear_avg_r2:.4f}")
    report.append(f"   - å…¶ä»–æ¨¡å‹å¹³å‡RÂ²: {other_avg_r2:.4f}")
    
    if tree_avg_r2 > max(linear_avg_r2, other_avg_r2):
        report.append("   â˜… æ ‘æ¨¡å‹æ•´ä½“è¡¨ç°æœ€ä½³ï¼Œè¯´æ˜æ•°æ®å­˜åœ¨å¤æ‚éçº¿æ€§å…³ç³»")
    elif linear_avg_r2 > max(tree_avg_r2, other_avg_r2):
        report.append("   â˜… çº¿æ€§æ¨¡å‹æ•´ä½“è¡¨ç°æœ€ä½³ï¼Œè¯´æ˜ç‰¹å¾ä¸ç›®æ ‡å˜é‡å­˜åœ¨è¾ƒå¼ºçº¿æ€§å…³ç³»")
    
    # 8.3 å…³é”®ç‰¹å¾è¯†åˆ«
    report.append("\n3. å…³é”®å½±å“å› ç´ :")
    
    if importance_results or shap_results:
        from collections import Counter
        all_important_features = []
        
        if importance_results and all_top5_features:
            feature_counts = Counter(all_top5_features)
            all_important_features.extend([f for f, c in feature_counts.most_common(5)])
        
        if shap_results and all_shap_top5:
            shap_counts = Counter(all_shap_top5)
            all_important_features.extend([f for f, c in shap_counts.most_common(5)])
        
        # å»é‡å¹¶ç»Ÿè®¡
        final_important = Counter(all_important_features).most_common(5)
        
        report.append("   æ ¹æ®ç‰¹å¾é‡è¦æ€§å’ŒSHAPå€¼ç»¼åˆåˆ†æï¼Œå½±å“PMæµ“åº¦çš„å…³é”®å› ç´ ä¸º:")
        for rank, (feature, count) in enumerate(final_important, 1):
            report.append(f"   {rank}. {feature}")
    
    # 8.4 è¿‡æ‹Ÿåˆé£é™©è¯„ä¼°
    report.append("\n4. è¿‡æ‹Ÿåˆé£é™©è¯„ä¼°:")
    
    overfit_models = []
    good_models = []
    
    for model_name in results.keys():
        gap = results[model_name]['train_r2'] - results[model_name]['test_r2']
        if gap > 0.10:
            overfit_models.append((model_name, gap))
        else:
            good_models.append((model_name, gap))
    
    if overfit_models:
        report.append(f"   - {len(overfit_models)}ä¸ªæ¨¡å‹å­˜åœ¨è¿‡æ‹Ÿåˆé£é™©:")
        for model, gap in sorted(overfit_models, key=lambda x: x[1], reverse=True):
            report.append(f"     â€¢ {model} (å·®è·: {gap:.4f})")
    
    if good_models:
        report.append(f"   - {len(good_models)}ä¸ªæ¨¡å‹æ³›åŒ–èƒ½åŠ›è‰¯å¥½:")
        for model, gap in sorted(good_models, key=lambda x: x[1]):
            report.append(f"     â€¢ {model} (å·®è·: {gap:.4f})")
    
    report.append("\n")
    
    # 9. ç»“è®ºä¸å»ºè®®
    report.append("ä¹ã€ç»“è®ºä¸å»ºè®®")
    report.append("-" * 120)
    
    report.append("\nã€æ¨¡å‹é€‰æ‹©å»ºè®®ã€‘")
    
    if best_r2 >= 0.9:
        report.append(f"âœ“ æ¨èä½¿ç”¨ {best_overall} æ¨¡å‹è¿›è¡ŒPMæµ“åº¦é¢„æµ‹")
        report.append("  è¯¥æ¨¡å‹é¢„æµ‹æ€§èƒ½ä¼˜ç§€ï¼ŒRÂ²è¶…è¿‡0.9ï¼Œå¯ç›´æ¥ç”¨äºå®é™…åº”ç”¨")
    elif best_r2 >= 0.8:
        report.append(f"âœ“ æ¨èä½¿ç”¨ {best_overall} æ¨¡å‹è¿›è¡ŒPMæµ“åº¦é¢„æµ‹")
        report.append("  è¯¥æ¨¡å‹é¢„æµ‹æ€§èƒ½è‰¯å¥½ï¼ŒRÂ²è¶…è¿‡0.8ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–åæŠ•å…¥ä½¿ç”¨")
    elif best_r2 >= 0.7:
        report.append(f"â—‹ å¯è€ƒè™‘ä½¿ç”¨ {best_overall} æ¨¡å‹ï¼Œä½†éœ€è¦è¿›ä¸€æ­¥æ”¹è¿›")
        report.append("  è¯¥æ¨¡å‹é¢„æµ‹æ€§èƒ½ä¸­ç­‰ï¼Œå»ºè®®:")
        report.append("    - æ”¶é›†æ›´å¤šè®­ç»ƒæ•°æ®")
        report.append("    - è¿›è¡Œæ›´æ·±å…¥çš„ç‰¹å¾å·¥ç¨‹")
        report.append("    - å°è¯•é›†æˆå­¦ä¹ æ–¹æ³•")
    else:
        report.append(f"âœ— å½“å‰æœ€ä½³æ¨¡å‹ {best_overall} çš„RÂ²ä»…ä¸º {best_r2:.4f}ï¼Œæ€§èƒ½ä¸è¶³")
        report.append("  å»ºè®®:")
        report.append("    - é‡æ–°å®¡è§†æ•°æ®è´¨é‡å’Œç‰¹å¾é€‰æ‹©")
        report.append("    - æ”¶é›†æ›´å¤šç›¸å…³ç‰¹å¾")
        report.append("    - æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ•°æ®æ³„æ¼æˆ–å¼‚å¸¸å€¼")
        report.append("    - è€ƒè™‘æ·±åº¦å­¦ä¹ æ–¹æ³•")
    
    report.append("\nã€ç‰¹å¾å·¥ç¨‹å»ºè®®ã€‘")
    
    if importance_results or shap_results:
        report.append("åŸºäºç‰¹å¾é‡è¦æ€§åˆ†æ:")
        report.append("  1. é‡ç‚¹å…³æ³¨é«˜é‡è¦æ€§ç‰¹å¾çš„æ•°æ®è´¨é‡")
        report.append("  2. è€ƒè™‘åˆ›å»ºé‡è¦ç‰¹å¾ä¹‹é—´çš„äº¤äº’é¡¹")
        report.append("  3. å¯¹ä½é‡è¦æ€§ç‰¹å¾è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œç®€åŒ–æ¨¡å‹")
        
        # è¯†åˆ«ä½é‡è¦æ€§ç‰¹å¾
        if importance_results:
            low_importance_features = set()
            for imp_df in importance_results.values():
                if imp_df is not None:
                    # å–é‡è¦æ€§æœ€ä½çš„5ä¸ªç‰¹å¾
                    low_features = imp_df.tail(5).index.tolist()
                    low_importance_features.update(low_features)
            
            if low_importance_features:
                report.append("\n  å¯è€ƒè™‘ç§»é™¤çš„ä½é‡è¦æ€§ç‰¹å¾:")
                for feat in sorted(low_importance_features)[:10]:
                    report.append(f"    - {feat}")
    
    report.append("\nã€æ•°æ®æ”¶é›†å»ºè®®ã€‘")
    report.append("  1. å¢åŠ æ—¶é—´åºåˆ—ç‰¹å¾ï¼ˆå¦‚å‰ä¸€æ—¶åˆ»çš„PMå€¼ï¼‰")
    report.append("  2. è¡¥å……æ°”è±¡æ•°æ®ï¼ˆå¦‚é™é›¨é‡ã€èƒ½è§åº¦ç­‰ï¼‰")
    report.append("  3. æ·»åŠ äººæµé‡ã€åˆ—è½¦é¢‘æ¬¡ç­‰è¿è¥æ•°æ®")
    report.append("  4. æ”¶é›†æ›´å¤šåŸå¸‚å’Œç«™ç‚¹çš„æ•°æ®ä»¥æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›")
    
    report.append("\nã€æ¨¡å‹éƒ¨ç½²å»ºè®®ã€‘")
    report.append(f"  1. ç”Ÿäº§ç¯å¢ƒæ¨èä½¿ç”¨: {best_overall}")
    
    # æ¨èå¤‡é€‰æ¨¡å‹
    if len(sorted_models) > 1:
        second_best = sorted_models[1][0]
        second_r2 = sorted_models[1][1]['test_r2']
        report.append(f"  2. å¤‡é€‰æ¨¡å‹: {second_best} (RÂ²={second_r2:.4f})")
    
    report.append("  3. å»ºç«‹æ¨¡å‹ç›‘æ§æœºåˆ¶:")
    report.append("     - å®šæœŸè¯„ä¼°æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„æ€§èƒ½")
    report.append("     - è®¾ç½®é¢„æµ‹è¯¯å·®é˜ˆå€¼å‘Šè­¦")
    report.append("     - æ¯å­£åº¦ä½¿ç”¨æ–°æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹")
    
    report.append("\nã€å®é™…åº”ç”¨å»ºè®®ã€‘")
    report.append("  1. é¢„è­¦ç³»ç»Ÿ:")
    report.append("     - å½“é¢„æµ‹PMæµ“åº¦è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œæå‰å¯åŠ¨é€šé£ç³»ç»Ÿ")
    report.append("     - åœ¨é«˜å³°æ—¶æ®µåŠ å¼ºç©ºæ°”è´¨é‡ç›‘æµ‹")
    
    report.append("\n  2. ä¼˜åŒ–æªæ–½:")
    report.append("     - æ ¹æ®å…³é”®å½±å“å› ç´ åˆ¶å®šé’ˆå¯¹æ€§æ”¹å–„æ–¹æ¡ˆ")
    report.append("     - åœ¨é«˜é£é™©æ—¶æ®µå’Œç«™ç‚¹å¢åŠ æ¸…æ´é¢‘æ¬¡")
    report.append("     - ä¼˜åŒ–é€šé£ç³»ç»Ÿè¿è¡Œç­–ç•¥")
    
    report.append("\n  3. æŒç»­æ”¹è¿›:")
    report.append("     - æ”¶é›†æ¨¡å‹é¢„æµ‹ä¸å®é™…å€¼çš„åå·®æ•°æ®")
    report.append("     - åˆ†æé¢„æµ‹å¤±è´¥çš„æ¡ˆä¾‹ï¼Œæ”¹è¿›æ¨¡å‹")
    report.append("     - ç»“åˆé¢†åŸŸä¸“å®¶çŸ¥è¯†ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹")
    
    report.append("\nã€æ¨¡å‹å¯è§£é‡Šæ€§ã€‘")
    
    if shap_results:
        report.append("  âœ“ å·²ç”ŸæˆSHAPå€¼åˆ†æï¼Œå¯ç”¨äº:")
        report.append("    - å‘ç®¡ç†å±‚è§£é‡Šæ¨¡å‹é¢„æµ‹ç»“æœ")
        report.append("    - è¯†åˆ«å¼‚å¸¸é¢„æµ‹çš„åŸå› ")
        report.append("    - éªŒè¯æ¨¡å‹å†³ç­–çš„åˆç†æ€§")
        report.append("    - æŒ‡å¯¼è¿è¥ä¼˜åŒ–å†³ç­–")
    
    report.append("\nã€é£é™©æç¤ºã€‘")
    report.append("  1. æ¨¡å‹é¢„æµ‹å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œå»ºè®®ç»“åˆå®é™…ç›‘æµ‹æ•°æ®ä½¿ç”¨")
    report.append("  2. å½“è¾“å…¥ç‰¹å¾è¶…å‡ºè®­ç»ƒæ•°æ®èŒƒå›´æ—¶ï¼Œé¢„æµ‹å¯èƒ½ä¸å‡†ç¡®")
    report.append("  3. æ¨¡å‹æœªè€ƒè™‘çªå‘äº‹ä»¶ï¼ˆå¦‚è®¾å¤‡æ•…éšœã€æç«¯å¤©æ°”ï¼‰çš„å½±å“")
    report.append("  4. éœ€è¦å®šæœŸæ›´æ–°æ¨¡å‹ä»¥é€‚åº”ç¯å¢ƒå˜åŒ–")
    
    report.append("\n")
    report.append("=" * 120)
    report.append("æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
    report.append("=" * 120)
    report.append(f"\nåˆ†æäººå‘˜: æ•°æ®åˆ†æç³»ç»Ÿ")
    report.append(f"æŠ¥å‘Šç‰ˆæœ¬: v5.0 (ä¼˜åŒ–ç‰ˆ)")
    report.append(f"æ¨¡å‹æ•°é‡: {len(results)} ä¸ª")
    report.append("\n")
    
    # ä¿å­˜æŠ¥å‘Š
    report_text = "\n".join(report)
    with open(out_path('analysis_report.txt'), 'w', encoding='utf-8') as f:
        f.write(report_text)
    
    print("\n" + report_text)
    print(f"\nâœ“ æŠ¥å‘Šå·²ä¿å­˜è‡³: {out_path('analysis_report.txt')}")
    
    return report_text
# ==================== 9. ä¿å­˜æ¨¡å‹å’Œç»“æœ ====================
def save_results(results, trained_models, importance_results, shap_results):
    """ä¿å­˜æ¨¡å‹å’Œåˆ†æç»“æœ"""
    
    print("\n" + "=" * 100)
    print("æ­¥éª¤ 7: ä¿å­˜æ¨¡å‹å’Œç»“æœ")
    print("=" * 100)
    
    import pickle
    
    # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
    print("\nä¿å­˜è®­ç»ƒæ¨¡å‹...")
    for model_name, model_info in trained_models.items():
        filename = out_path(f"model_{model_name.replace(' ', '_')}.pkl")
        with open(filename, 'wb') as f:
            pickle.dump(model_info['model'], f)
        print(f"âœ“ ä¿å­˜: {filename}")
    
    # ä¿å­˜ç»“æœæ‘˜è¦
    print("\nä¿å­˜ç»“æœæ‘˜è¦...")
    results_summary = pd.DataFrame({
        'æ¨¡å‹': list(results.keys()),
        'è®­ç»ƒé›†RÂ²': [results[m]['train_r2'] for m in results.keys()],
        'æµ‹è¯•é›†RÂ²': [results[m]['test_r2'] for m in results.keys()],
                'æµ‹è¯•é›†RMSE': [results[m]['test_rmse'] for m in results.keys()],
        'æµ‹è¯•é›†MAE': [results[m]['test_mae'] for m in results.keys()],
        'æµ‹è¯•é›†MAPE': [results[m]['test_mape'] for m in results.keys()],
        'äº¤å‰éªŒè¯RÂ²å‡å€¼': [results[m]['cv_r2_mean'] for m in results.keys()],
        'äº¤å‰éªŒè¯RÂ²æ ‡å‡†å·®': [results[m]['cv_r2_std'] for m in results.keys()],
        'è¿‡æ‹Ÿåˆå·®è·': [results[m]['overfit_gap'] for m in results.keys()]
    })
    results_summary.to_csv(out_path('model_performance_summary.csv'), index=False, encoding='utf-8-sig')
    print("âœ“ ä¿å­˜: model_performance_summary.csv")
    
    # ä¿å­˜ç‰¹å¾é‡è¦æ€§
    if importance_results:
        print("\nä¿å­˜ç‰¹å¾é‡è¦æ€§...")
        with pd.ExcelWriter(out_path('feature_importance_summary.xlsx'), engine='openpyxl') as writer:
            for model_name, imp_df in importance_results.items():
                if imp_df is not None:
                    sheet_name = model_name[:31]  # Excel sheetåç§°é™åˆ¶
                    imp_df.to_frame(name='Importance').to_excel(writer, sheet_name=sheet_name, index=True)
        print("âœ“ ä¿å­˜: feature_importance_summary.xlsx")
    
    # ä¿å­˜SHAPé‡è¦æ€§
    if shap_results:
        print("\nä¿å­˜SHAPé‡è¦æ€§...")
        with pd.ExcelWriter(out_path('shap_importance_summary.xlsx'), engine='openpyxl') as writer:
            for model_name, shap_data in shap_results.items():
                if 'importance' in shap_data:
                    sheet_name = model_name[:31]
                    shap_data['importance'].to_excel(writer, sheet_name=sheet_name, index=False)
        print("âœ“ ä¿å­˜: shap_importance_summary.xlsx")
    
    # ä¿å­˜æœ€ä½³è¶…å‚æ•°
    print("\nä¿å­˜æœ€ä½³è¶…å‚æ•°...")
    best_params_df = pd.DataFrame([
        {'æ¨¡å‹': model_name, 'å‚æ•°': str(results[model_name]['best_params'])}
        for model_name in results.keys()
    ])
    best_params_df.to_csv(out_path('best_hyperparameters.csv'), index=False, encoding='utf-8-sig')
    print("âœ“ ä¿å­˜: best_hyperparameters.csv")
    
    print("\næ‰€æœ‰ç»“æœå·²ä¿å­˜ï¼")
    # ==================== 10. ä¸»å‡½æ•° ====================
def main(file_path='2.xlsx'):
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    print("\nå¼€å§‹åˆ†ææµç¨‹...\n")
    try:
        # æ­¥éª¤1: åŠ è½½æ•°æ®
        X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, feature_names = \
        load_and_preprocess_data(file_path)
        
        # ç¡®ä¿X_train_scaledå’ŒX_test_scaledè¢«æ­£ç¡®å®šä¹‰ï¼ˆæ·»åŠ é¢å¤–ä¿æŠ¤ï¼‰
        if X_train_scaled is None or X_test_scaled is None:
            print("è­¦å‘Š: X_train_scaledå’ŒX_test_scaledæœªå®šä¹‰ï¼Œä½¿ç”¨åŸå§‹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–")
            X_train_scaled = X_train.copy()
            X_test_scaled = X_test.copy()
        # ==================== æ˜¯å¦å¯ç”¨æ•°æ®å¢å¼º ====================
        USE_AUGMENT = False # âœ… å¼€å…³
        N_AUG = 2 # å°æ ·æœ¬å»ºè®®1ï¼ˆæœ€å¤š2ï¼‰ï¼Œæ¯ä¸ªæ ·æœ¬ç”Ÿæˆ1ä¸ªå¢å¼ºæ ·æœ¬
        NOISE_SCALE = 0.15 # å°æ ·æœ¬æ ¸å¿ƒï¼šä¸è¶…è¿‡0.4
        if USE_AUGMENT:
            print("\n>>> å¯ç”¨æ®‹å·®é©±åŠ¨æ•°æ®å¢å¼ºï¼ˆå°æ ·æœ¬ä¼˜åŒ–ç‰ˆï¼‰")
            print(f" åŸå§‹è®­ç»ƒæ ·æœ¬æ•°: {len(X_train)}")
            X_aug, y_aug = residual_based_augmentation(
                X_train, y_train, n_aug=N_AUG, noise_scale=NOISE_SCALE
            )
            # åˆå¹¶åŸå§‹ + å¢å¼ºæ•°æ®
            X_train = pd.concat([X_train, X_aug], axis=0)
            y_train = pd.concat([y_train, y_aug], axis=0)
            print(f" å¢å¼ºåè®­ç»ƒæ ·æœ¬æ•°: {len(X_train)}")
            # é‡æ–°æ ‡å‡†åŒ–ï¼ˆå¿…é¡»ä¿ç•™ï¼å¢å¼ºåç‰¹å¾åˆ†å¸ƒæœ‰å¾®å°å˜åŒ–ï¼‰
            scaler = RobustScaler()
            X_train_scaled = pd.DataFrame(
                scaler.fit_transform(X_train), 
                columns=X_train.columns, 
                index=X_train.index
            )
            X_test_scaled = pd.DataFrame(
                scaler.transform(X_test), 
                columns=X_test.columns, 
                index=X_test.index
            )
        
        # æ­¥éª¤2: è®­ç»ƒæ¨¡å‹
        results, trained_models = train_and_evaluate_models(
            X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled
        )
        
        # æ­¥éª¤3: ç‰¹å¾é‡è¦æ€§åˆ†æ
        importance_results = analyze_feature_importance(trained_models, X_train, X_test, y_train, y_test, feature_names)
        
        # æ­¥éª¤4: SHAPåˆ†æ
        shap_results = analyze_shap_values(
            trained_models, X_train, X_test,
            X_train_scaled, X_test_scaled, feature_names, y_train, y_test
        )
        
        # æ­¥éª¤5: ç”Ÿæˆå¯è§†åŒ–
        create_visualizations(results, importance_results, shap_results, 
                             feature_names, y_test)
        
        # æ­¥éª¤6: ç”ŸæˆæŠ¥å‘Š
        generate_report(results, importance_results, shap_results, feature_names)
        
        # æ­¥éª¤7: ä¿å­˜ç»“æœ
        save_results(results, trained_models, importance_results, shap_results)
        
        print("\n" + "=" * 100)
        print("åˆ†æå®Œæˆï¼")
        print("=" * 100)
        print(f"\nğŸ“ æ‰€æœ‰è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜è‡³ç›®å½•: {OUTPUT_DIR}")
        print("\nç”Ÿæˆçš„æ–‡ä»¶æ¸…å•:")
        print("\nã€å¯è§†åŒ–å›¾è¡¨ã€‘")
        print("  1.  model_performance_comparison.png    - æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾")
        print("  2.  prediction_vs_actual.png            - é¢„æµ‹å€¼vsçœŸå®å€¼æ•£ç‚¹å›¾")
        print("  3.  residual_analysis.png               - æ®‹å·®åˆ†æå›¾")
        print("  4.  feature_importance.png              - ç‰¹å¾é‡è¦æ€§å›¾")
        print("  5.  feature_importance_heatmap.png      - ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾")
        print("  6.  model_radar_chart.png               - æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾")
        print("  7.  error_distribution.png              - è¯¯å·®åˆ†å¸ƒç®±çº¿å›¾")
        print("  8.  overfitting_diagnosis.png           - è¿‡æ‹Ÿåˆè¯Šæ–­å›¾")
        print("  9.  shap_importance_heatmap.png         - SHAPé‡è¦æ€§çƒ­åŠ›å›¾")
        
        print("\nã€SHAPå¯è§†åŒ–ã€‘(æ¯ä¸ªæ¨¡å‹)")
        for model_name in shap_results.keys():
            model_file = model_name.replace(' ', '_')
            print(f"  -  shap_summary_{model_file}.png        - SHAPæ‘˜è¦å›¾")
            print(f"  -  shap_bar_{model_file}.png            - SHAPæ¡å½¢å›¾")
            print(f"  -  shap_waterfall_{model_file}.png      - SHAPç€‘å¸ƒå›¾")
        
        print("\nã€åˆ†ææŠ¥å‘Šã€‘")
        print("  10. analysis_report.txt                 - è¯¦ç»†åˆ†ææŠ¥å‘Š")
        
        print("\nã€æ•°æ®æ–‡ä»¶ã€‘")
        print("  11. model_performance_summary.csv       - æ¨¡å‹æ€§èƒ½æ±‡æ€»")
        print("  12. feature_importance_summary.xlsx     - ç‰¹å¾é‡è¦æ€§æ±‡æ€»")
        print("  13. shap_importance_summary.xlsx        - SHAPé‡è¦æ€§æ±‡æ€»")
        print("  14. best_hyperparameters.csv            - æœ€ä½³è¶…å‚æ•°é…ç½®")
        
        print("\nã€æ¨¡å‹æ–‡ä»¶ã€‘")
        for model_name in trained_models.keys():
            print(f"  -  model_{model_name.replace(' ', '_')}.pkl")
        
        print("\n" + "=" * 100)
        print("æ„Ÿè°¢ä½¿ç”¨åœ°é“é¢—ç²’ç‰©æµ“åº¦é¢„æµ‹åˆ†æç³»ç»Ÿ v5.0ï¼")
        print("=" * 100)
        print("\n")
        
        return results, trained_models, importance_results, shap_results
        
    except FileNotFoundError:
        print(f"\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ '{file_path}'")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹ï¼Œæˆ–æä¾›æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„")
        return None, None, None, None
        
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, None, None, None
# ==================== 11. æ‰§è¡Œä¸»å‡½æ•° ====================
if __name__ == "__main__":
    # ä¿®æ”¹ä¸ºä½ çš„å®é™…æ–‡ä»¶è·¯å¾„
    data_file = "E:\\2021-æ–‡ä»¶A\\æ–‡ç« \\paper6 åœ°é“é¢—ç²’ç‰©å½±å“å› ç´ åˆ†æ\\Factor.xlsx"
    
    # æ‰§è¡Œåˆ†æ
    results, trained_models, importance_results, shap_results = main(data_file)
    
    # å¦‚æœéœ€è¦ï¼Œå¯ä»¥è¿›ä¸€æ­¥åˆ†æç»“æœ
    if results is not None:
        print("\n" + "=" * 100)
        print("å¿«é€ŸæŸ¥çœ‹æœ€ä½³æ¨¡å‹")
        print("=" * 100)
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model_name = max(results.items(), key=lambda x: x[1]['test_r2'])[0]
        best_results = results[best_model_name]
        
        print(f"\næœ€ä½³æ¨¡å‹: {best_model_name}")
        print(f"  æµ‹è¯•é›† RÂ²:    {best_results['test_r2']:.4f}")
        print(f"  æµ‹è¯•é›† RMSE:  {best_results['test_rmse']:.4f}")
        print(f"  æµ‹è¯•é›† MAE:   {best_results['test_mae']:.4f}")
        print(f"  æµ‹è¯•é›† MAPE:  {best_results['test_mape']:.2f}%")
        print(f"  äº¤å‰éªŒè¯ RÂ²:  {best_results['cv_r2_mean']:.4f} Â± {best_results['cv_r2_std']:.4f}")
        print(f"  è¿‡æ‹Ÿåˆå·®è·:   {best_results['overfit_gap']:+.4f}")
        
        print("\næœ€ä½³è¶…å‚æ•°:")
        for param, value in best_results['best_params'].items():
            print(f"  {param}: {value}")
        
        # æ˜¾ç¤ºTop 5ç‰¹å¾
        if importance_results and best_model_name in importance_results and importance_results[best_model_name] is not None:
            print(f"\nTop 5 é‡è¦ç‰¹å¾ ({best_model_name}):")
            top5 = importance_results[best_model_name].head(5)
            for idx, row in top5.items():
                print(f"  {idx}: {row:.6f}")
        
        # æ˜¾ç¤ºTop 5 SHAPç‰¹å¾
        if shap_results and best_model_name in shap_results:
            if 'importance' in shap_results[best_model_name]:
                print(f"\nTop 5 SHAPé‡è¦ç‰¹å¾ ({best_model_name}):")
                top5_shap = shap_results[best_model_name]['importance'].head(5)
                for idx, row in top5_shap.iterrows():
                    print(f"  {row['Feature']}: {row['Mean_Abs_SHAP']:.6f} {row['Direction']}")
        
        print("\n" + "=" * 100)
        
        # æä¾›ä½¿ç”¨å»ºè®®
        print("\nä½¿ç”¨å»ºè®®:")
        print("  1. æŸ¥çœ‹ 'analysis_report.txt' è·å–å®Œæ•´åˆ†ææŠ¥å‘Š")
        print("  2. æŸ¥çœ‹å„ç±»PNGå›¾è¡¨äº†è§£æ¨¡å‹æ€§èƒ½å’Œç‰¹å¾é‡è¦æ€§")
        print("  3. ä½¿ç”¨ä¿å­˜çš„.pklæ¨¡å‹æ–‡ä»¶è¿›è¡Œé¢„æµ‹")
        print("  4. æŸ¥çœ‹è¿‡æ‹Ÿåˆè¯Šæ–­å›¾è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›")
        
        print("\nç¤ºä¾‹ä»£ç  - åŠ è½½æ¨¡å‹è¿›è¡Œé¢„æµ‹:")
        print(f"""

        """)
        
        print("\n" + "=" * 100)
        print("æ€§èƒ½ä¼˜åŒ–æ€»ç»“")
        print("=" * 100)
        
        # ç»Ÿè®¡æ€§èƒ½æå‡
        print("\næœ¬æ¬¡ä¼˜åŒ–æªæ–½:")
        print("  âœ“ å»é™¤TabPFNæ¨¡å‹ï¼Œç®€åŒ–æ¨¡å‹é›†åˆ")
        print("  âœ“ æ–°å¢19ä¸ªé«˜çº§ç‰¹å¾ï¼ˆå¤šé¡¹å¼ã€äº¤äº’ã€å‘¨æœŸæ€§ç¼–ç ç­‰ï¼‰")
        print("  âœ“ æ‰©å¤§è¶…å‚æ•°æœç´¢ç©ºé—´ï¼Œå¢åŠ æœç´¢è¿­ä»£æ¬¡æ•°")
        print("  âœ“ ä¼˜åŒ–æ ‘æ¨¡å‹æ·±åº¦å’Œæ­£åˆ™åŒ–å¹³è¡¡")
        print("  âœ“ ä½¿ç”¨10æŠ˜äº¤å‰éªŒè¯æé«˜è¯„ä¼°ç¨³å®šæ€§")
        print("  âœ“ å¢å¼ºè¿‡æ‹Ÿåˆè¯Šæ–­å’Œå¯è§†åŒ–")
        
        # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹æ€§èƒ½
        print("\næ‰€æœ‰æ¨¡å‹æ€§èƒ½æ’å:")
        sorted_models = sorted(results.items(), key=lambda x: x[1]['test_r2'], reverse=True)
        print(f"\n{'æ’å':<6} {'æ¨¡å‹':<22} {'æµ‹è¯•RÂ²':<10} {'RMSE':<10} {'MAE':<10} {'è¿‡æ‹Ÿåˆ':<10}")
        print("-" * 80)
        for rank, (model_name, model_results) in enumerate(sorted_models, 1):
            gap = model_results['overfit_gap']
            gap_status = "ğŸŸ¢" if gap <= 0.05 else "ğŸŸ¡" if gap <= 0.12 else "ğŸŸ " if gap <= 0.20 else "ğŸ”´"
            print(f"{rank:<6} {model_name:<22} {model_results['test_r2']:<10.4f} "
                  f"{model_results['test_rmse']:<10.4f} {model_results['test_mae']:<10.4f} "
                  f"{gap_status} {gap:+.4f}")
        
        print("\n" + "=" * 100)
        print("é¢„æœŸæ€§èƒ½æå‡")
        print("=" * 100)
        print("\nä¸åŸç‰ˆæœ¬ç›¸æ¯”:")
        print("  â€¢ ç‰¹å¾æ•°é‡: 18 â†’ 37 (å¢åŠ 105%)")
        print("  â€¢ è¶…å‚æ•°æœç´¢: æ ‡å‡† â†’ æ‰©å±• (å¹³å‡å¢åŠ 40%æœç´¢ç©ºé—´)")
        print("  â€¢ äº¤å‰éªŒè¯: 5æŠ˜ â†’ 10æŠ˜ (æå‡è¯„ä¼°ç¨³å®šæ€§)")
        print("  â€¢ é¢„æœŸRÂ²æå‡: +2-5% (å–å†³äºæ•°æ®ç‰¹æ€§)")
        print("  â€¢ è¿‡æ‹Ÿåˆæ§åˆ¶: ä¿æŒä¸¥æ ¼çš„æ­£åˆ™åŒ–æœºåˆ¶")
        
        print("\n" + "=" * 100)
        print("ä¸‹ä¸€æ­¥å»ºè®®")
        print("=" * 100)
        print("\nå¦‚æœæ€§èƒ½ä»éœ€æå‡ï¼Œå¯ä»¥å°è¯•:")
        print("  1. ç‰¹å¾é€‰æ‹©: ä½¿ç”¨é€’å½’ç‰¹å¾æ¶ˆé™¤(RFE)ç­›é€‰æœ€ä¼˜ç‰¹å¾å­é›†")
        print("  2. é›†æˆä¼˜åŒ–: è°ƒæ•´Stackingçš„å…ƒæ¨¡å‹å’ŒåŸºæ¨¡å‹ç»„åˆ")
        print("  3. æ•°æ®å¢å¼º: ä½¿ç”¨SMOTEç­‰æ–¹æ³•å¢åŠ è®­ç»ƒæ ·æœ¬")
        print("  4. æ·±åº¦å­¦ä¹ : å°è¯•ç¥ç»ç½‘ç»œæ¨¡å‹(MLP, TabNet)")
        print("  5. æ—¶é—´åºåˆ—: å¦‚æœæ•°æ®æœ‰æ—¶é—´é¡ºåºï¼Œè€ƒè™‘LSTM/GRU")
        print("  6. è´å¶æ–¯ä¼˜åŒ–: ä½¿ç”¨Optunaç­‰å·¥å…·è¿›è¡Œæ›´æ™ºèƒ½çš„è¶…å‚æ•°æœç´¢")
        
        print("\n" + "=" * 100) 
